# （转载）Mac OS X 背后的故事
文 / 王越

## Mac OS X 背后的故事（一）力挽狂澜的Ellen Hancock
从本期开始，我们将在杂志上连载一系列关于Mac OS X发展历史的文章。本系列将为大家介绍Mac OS X的发行版本、技术历史、相关人物等内容。本文是系列连载的第一篇。
Ellen Hancock曾任苹果公司技术总监
故事还得从20世纪90年代说起。Ellen Hancock是本文的主人公，也是一位女英雄。她因在IBM的经历而被人们所熟悉。1966-1995年间，Ellen Hancock在IBM共工作了29年。1985年，她成为IBM的副主席。在1986-1988年间，Ellen Hancock担任过IBM通信产品的主席，并在1992年被选为资深副总裁。1995年9月，她被时任美国国家半导体（National Semiconductor）CEO的Gil Amelio忽悠，跳槽来到这个企业，做执行副总裁。她在这里带领团队完成了CompactRISC架构，这个架构事后成为ARM7系列的前身。很多人早已经把她忘了，也很少有人能够在回忆时将她和Mac OS X联系起来。但事实上，她是让苹果放弃Copland转而购买NeXT的关键人物。
早在1994年，Gil Amelio就找好了下家Apple，成为Apple董事会的成员。1997年2月，Gil Amelio从National Semiconductor辞职，并成为Apple的CEO。为了紧跟老板的召唤，Ellen Hancock再次被忽悠，来到了当时危机四伏的Apple。这时是1996年5月，为什么是危机四伏呢？还得从早先的事情说起。
20世纪80年代，卖可乐的John Sculley成为Apple的CEO，随之Steve Jobs被轰出Apple。毕竟可乐和计算机不是一回事，因此不管是硬件还是Mac OS，整个公司的开发项目越来越受阻。而且由于先天的不足，Mac OS从诞生之初就不具有一个现代操作系统所应有的特性。所以，在1987年，开发下一代操作系统的计划呼之欲出。具体的规划是，把新的系统所需要的功能，写在一堆卡片上。短期可实现的目标，比如增加颜色支持（当时计算机仍是黑白的），写在蓝色的卡片上；长期的目标，比如多任务功能，写在粉色的卡片上；而在可预见的未来都无法实现的长期的目标，比如加一个纯物件导向的文件系统，就写在红色的卡片上。在这样的思路下，Mac OS的开发团队马上就被分成两个组，一个叫蓝组，目标是在1991年，发布一个关于Mac OS的更新版本；另一个叫粉组，和蓝组同时工作，计划在1993年，发布一个全新的操作系统。
1991年5月13日，蓝组顺利按时完成开发任务，发布了Mac OS 7（一般被称为System 7），而粉组却没做出什么有实际用途的东西来，因此接连跳票。而且，由于Mac OS 7的发布往往缺乏人手，为了保持正常发布，常常需要从粉组抽调人员参加蓝组的开发，再加上Apple当时重心放在了和IBM等公司的合作上（Taligent项目）而不是在粉组上，最终导致了粉组项目夭折。而本来Apple指望和IBM合作的Taligent项目能开发出一个可用的新系统，但后来IBM不跟Apple继续玩了，因而Taligent的果子又吃不到，Apple相当郁闷。 这时由于Mac OS有先天不足（单任务，没有内存保护），再加上Apple以及第三方软件的无限量增加（在这段时期，单Apple自己就已经加入了QuickDraw、PowerTalk、QuickTime等软件和技术，每一个都比Mac OS本身来得大），Mac OS的问题终于大爆发。上个世纪90年代，Mac OS给人的印象就是很不稳定、经常崩溃，同Windows 95留给PC用户的印象差不多，甚至更甚。
Taligent项目挂掉后，Apple自己尝试过十多个不同的内部项目，但大多没做多久就夭折了。而这时正是Windows NT走向成熟的关键时期。眼看着日子逐渐变得不好过了，Apple开始重新开始考虑建立下一代操作系统的事情。1994年，Mac OS 7.5（Mozart）发布后，Apple推出新规划，建立一个全新的操作系统，以Copland命名（纪念 Aaron Copland，Mac OS的发布以音乐家名字命名，和Mac OS X后使用猫科动物名字很不一样），这个项目将有一个全新的内核，具有类似Windows NT 内核的所有高级特性，而老的软件都当作独立的进程模拟运行。这个项目时间紧、任务重，1995年3月公布计划，预期1996年发布。而Copland后的版本Gershwin（纪念George Gershwin），预计1997年发布，将重写Mac的所有系统主要部件，以适合新内核的各种特性。
Copland将使用微内核技术，只做任务和内存分配。除此之外的所有功能，比如文件系统、硬件驱动等作为微内核上的服务运行。而Mac OS的所有用户界面功能将成为一个独立的框架，称为蓝盒（Blue Box，今后介绍Mac OS X时，我们还会遇到这个词）。所有的任务相互独立，占用独立内存，也可以用IPC相互交流。学过操作系统的人都知道，微内核是当时的一个热词，一个系统只有被称为微内核才可被看作是先进的，当时还有针对Linux系统的著名的Tanenbaum-Torvalds笔战。但事实证明，所有本来想做成微内核系统的成功项目都放弃了原先的设计（包括NeXTSTEP、Windows NT），因为这种类似Mach微内核的系统往往难产，GNU/Mach + Hurd之类的项目做到现在经过了20年，仍未成事，一年内搞一个微内核系统谈何容易。
微内核还没搞成，Apple几乎所有开发组的成员都来添乱。大家都说自己做的东西很重要，一定要加入Copland开发组，所以QuickDraw GX、OpenDoc之类的开发组产品成为新系统的核心组件，甚至类似用户界面皮肤之类的开发组都来凑热闹，马上就使Copland成为一个无法维护的项目。开出的计划越来越长，项目越来越多，但相关进展越来越少，完成速度越来越慢。即便做出了产品，连测试人手都不够。1995年就有工程师指出，在1996年发布Copland纯粹是幻想，能1997年发布就不错了。
1996年，Gil Amelio已经掌权。在苹果电脑全球研发者大会上他开心地宣布，传说中的Copland，也就是System 8的开发版会在当年夏天发布，而正式版在秋天就可以送到每位用户手上。时任TidBITs编辑的Matt Neuburg有幸见到了这个传说中的系统。令他大吃一惊的是，这个系统在当时只能打开或关闭文件，而无法对文本文件进行编辑，甚至所有用户界面的文本框都不能输字。哪怕什么都没做，整个系统也会随机崩溃，而崩溃甚至会造成文件系统损坏。参加演示的苹果员工，则需要不断守在旁边，他们的工作是不断地格式化已崩溃的计算机磁盘，然后重装系统。那年夏天，第零个测试版送到一小簇不明真相的开发者手中，把那些脆弱的没见过世面的人吓得半死。就连Apple内部都开玩笑说Copland的正式发布日期可能得推迟到2030年。
Gil Amelio心急如焚，希望Copland快点走到正道上来。作为Gil Amelio永远的好朋友，Ellen Hancock就在这个乱糟糟的时候来到了Apple。她的职务，正是担任这个乱糟糟项目的负责人。她亲自下访各小组体察民情，了解情况。毕竟在IBM干了近三十年，她依靠自己过人的判断力在2~3个月内便得出结论，Copland这个项目是没有指望的，就按目前Apple这样的状态，Copland永远都不可能发布，还不如早点取消了好。在短期内，先把 Copland中的一些有用的成果一点点合并到老的Mac OS中，并且抓紧从外部购买一个全新系统来满足Apple的需要。正是她的这个结论，结束了Apple长达五年的纠结，使公司重新走向正轨。整个PC的黄金时代已经过去，Apple想要翻身，还有很长一段路要走。Gil Amelio支持了Ellen Hancock的计划。1996年8月，Apple取消Copland项目。开发预览版的CD封套都已制完，每个邮包上的地址都已打印就续，而CD却从未曾制出。
1996-1998年是Apple最混乱的几年。在商业上，有一阵曾传出Apple要被Sun收购的消息。更有意思的是，《连线》杂志在1997年的六月还发表了一篇文章，名为《101种拯救Apple的方法》，其中一条说最好的方式是Apple让自己被Motorola买下，成为Motorola的一个部门，做 PowerPC 系列产品。以当时的眼光来看这些建议非常讽刺好笑，以今天的眼光看更为好笑。而Ellen Hancock在这段时间内的出色工作，成功地挽救了Apple。
首先，Ellen Hancock的对内政策是继续Mac OS 7.5的开发工作，一步步把Copland中的技术并到7.5中。同时，也大量购买第三方的系统增强包，包括插件管理工具、层次化菜单等技术。Apple把它们买过来，整合到现有的系统中。整个老系统在新系统尚未完成的时候不断更新，至2000年已出到9.0版，尽可能地留住了老用户。并且，前面提到的蓝盒（Blue Box）也作为后来新Mac OS X系统的一部分，支持用户运行经典Mac OS的程序。
而对外政策更是一个大手笔。Ellen Hancock协助Gil Amelio在Apple之外找寻操作系统技术。在IBM和Microsoft合作Big Blue的经验告诉她，购买一个操作系统的使用权问题多多，最好的计划是整个一并买下来。因此，Gil Amelio开始和当时看好的Be谈，却因价格问题没有成功，最终转而收购了NeXT。而Apple合并NeXT后，NeXTSTEP就演化为Rhapsody，并最终成为Mac OS X。这些事情我们今后会详细再谈。
买完NeXT后，Steve Jobs执政，Gil Amelio因任CEO期间Apple亏损严重而被炒。Steve Jobs把信得过的人（很多是前NeXT员工）拉拢到周围，开始新政，而同Gil Amelio有关的Ellen Hancock则在人事变动中被疏远。Steve Jobs甚至在很多场合称她为“笨蛋”。Ellen Hancock最终于1998年主动辞职。事后同Gil Amelio以及Apple的创始人之一Steve Wozniak一同创业，但始终不景气，她的辉煌时代已经过去。
Gil Amelio总结他在Apple时期的工作时说：“Apple是一艘底部有洞漏水的船，而我的工作是把这船引向正道。”（Apple is like a ship with a hole in a bottom, leaking water, and my job is to get this ship pointed in the right direction. ）Ellen Hancock虽然同Gil Amelio一样，不知如何去堵这个漏水的洞，但正是由于她在Apple的出色表现，不但把船引到了正道上，还找来了有能力堵这个洞的人。

## Mac OS X 背后的故事（二）——Linus Torvalds的短视
《Mac OS X背后的故事》系列文章将为大家介绍Mac OS X的发行版本、技术历史、相关人物等内容。本文是系列连载的第二篇，主要的故事来源是Linus Torvalds的自传《Just for Fun: The Story of an Accidental Revolutionary》。

Steve Jobs于1997年回归Apple
Steve Jobs对Mac OS X的考虑
1997年，Steve Jobs回归，开发下一代操作系统的工作被提上日程。此刻的时代背景是像Linux这样的开源软件大行其道。随着网络的发展，使得像Red Hat、VA Linux之类的企业成为爆发户，把泡沫越吹越大。Steve Jobs承认Linux的好处，甚至在若干年后介绍Mac OS X底层的Darwin时还不忘在幻灯片上写道：Darwin是类似Linux的系统。而当时精明的Steve Job在考虑下面几个问题。
第一，NeXTSTEP的内核和外围工具中，BSD代码维护起来需要大量人力，而且各分支的BSD发展显然不如Linux快。很多功能都没有，需要Apple自己做。
第二，像Apple这样的小公司，需要借力打力。Apple的主要竞争对手是Microsoft，而开源软件的矛头也是Microsoft，如果联合起来干革命，不但能让自己得到一个好名声（Apple事后一直自称是最大的开源软件公司），也可以获得可观利益，从而对Microsoft造成压力。
第三，也是最重要的，联合各开源组织能够推动Mac OS的发展。毕竟开源软件中像GCC之类都是很成熟的项目，Apple用起来省时省力，投点钱就有大效益，多好。
所以，把Linux内核作为Mac OS X的重要组成部分的想法被这位伟大的智者想了出来。Apple之前也有开发Linux的经验，比如在Steve Jobs回归之前，Apple就和OSF合作开始把Mach内核移植到PowerPC上（Apple是最大的PowerPC玩家，而OSF是最大的Mach玩家），并把Linux作为服务跑在Mach上。这个系统就是MkLinux，我们在后续的连载中还会提到这个系统，因为它不但对Linux的移植性作出了重要的贡献，也对后来的Mac OS X的XNU内核技术起到了相当重要的作用。
如果可以采用Linux作为系统重要组成部分，并且这个构想能够取得在开源软件界呼风唤雨的Linus Torvalds的认同，就能靠他在社区鼓动一大群开发者皈依Apple麾下，这是Apple很想看到的给力结局。有了这个指导思想，他便让秘书给Linux的开发者Linus Torvalds发了一个邮件，问他是不是有一到两小时的时间和Steve Jobs会面。不明真相的Linus Torvalds收到邮件后相当高兴，因为这是他第一次有机会去硅谷观摩。
无果而终的会面
Apple总部Infinity Loop终于迎来了这位稀客，Steve Jobs亲自接见，而先前任NeXT技术总监的Avie Tevanian（这人的故事我们今后会提到）也参加了这次会谈。不用多说，这次讨论的内容自然是还处于未知状态的Mac OS X。讨论算不上正式，但Linus Torvalds的愤青个性，却让谈判陷入僵局。
Steve Jobs自然搬出他1997年回归之际在MacWorld讲话时的那套理论，Apple虽然很颓，但骨子里是个牛逼的公司。全世界桌面领域的真正玩家就两个，一个是Apple，另一个是Microsoft，两者加起来，构成百分之百的桌面用户群。所以，Linus同学，你就从了我们吧，如果你从了我们，让我们把Mac架在Linux上，一大批桌面用户就是Linux用户啦，前景可是一片大好！
而Linus Torvalds那时候牛啊，诸多大公司如IBM、Red Hat都围着他转。他可是企业家中的大红人，像Apple这样的企业根本就不在他眼里。作为一个开源软件的革命家，在他的想象中Linux的潜在用户应该比Apple还多。他始终相信，按照目前开源软件的发展态势，自己很快就能在桌面领域分到一杯羹。而且这个命题在他这种古怪性格下的直接推论是，即使我能占领桌面领域，我也要摆出一副不在乎这个领域的态度来。所以实际上Steve Jobs的开场白就失败了。
接着，Avie Tevanian向Linus Torvalds介绍了整个计划。他们想把Mach和Linux内核合并起来作为Mac OS X的基础，我估计Linus Torvalds是听错了（因为Avie Tevanian很早就意识到相比于微内核，混合内核有明显优势），他以为Apple想把Linux作为Mach的一个服务来跑（当然我个人认为，即使是合并Mach和Linux成为混合内核，依Linus Torvalds的愤青性格，依然是不可能接受的），这正让他回想到先前和Tanenbaum教授的笔战。并且，他也知道Apple和IBM合搞的失败项目Taligent正是用Mach的。
Linus Torvalds对于微内核有他自己的看法，之前也曾在不同的地方表述过。若把关于微内核的笔战去掉限制级敏感词的话可概括成两方面。一方面，设计一个微内核和相关的服务，可能造成各种设计上的灾难。GNU/Hurd早在八十年代末就考虑尝试在Mach上写一系列Unix的服务层，结果他们始终无法搞明白到底是让这些服务先发消息到另几个服务呢，还是考虑其他方案。所以直到2011年我写这篇文章时，Hurd项目依然处于半死不活的状态。而另一方面，微内核的效率无法和传统内核相比，最简单的系统调用会涉及一系列底层服务的互相通信。所以很多研究者着手研究如何把微内核的效率提上去，结果就导致微内核变得更加复杂。能提高微内核效率的很多研究成果都已在Mach项目中实现了。而在Linus Torvalds看来这恰使Mach成为了一个非常复杂的项目，并且效率也不怎么高。
会谈时坐一旁的Avie Tevanian事实上是Mach最早的开发者之一，他热情地给Linus讲述Mac OS X系统蓝图。而Linus实际上早就不耐烦了。比如，Mac OS X中，有一个模拟层，可让用户使用经典的Mac OS程序。这个技术极类似于现在跑在Unix系统上执行Windows程序的Wine。Apple当时的考虑是这样，因为老的Mac OS在设计API时，就没有考虑到类似内存保护之类的问题，所以这层API必须废掉，Mac OS X中所有的新程序必须采用NeXT的那套更先进的API（根据我的考证，当时还没有Carbon这样的想法，而且事实上Carbon不管在API还是ABI上都和经典Mac OS不兼容）。而短期内已有的软件又不可能快速重写迁移至Mac OS X。所以，如果用户需要使用老版Mac OS的第三方应用程序，就可以使用Apple提供的这个兼容层。但是由于刚才提到的原因，老版程序并不享受新版程序的待遇，因为模拟器本身运行多个老Mac OS任务时，和原先老版Mac OS一样，实际上只有一个进程，没有内存保护。这样做的好处是明显的，因为一方面老的程序在Mac OS X发布之初还能用，另一方面Apple又和老技术划清了界限，逼着开发者使用新技术，技术方面的原因是最重要的。但这个看似很正确的技术在Linus Torvalds看来是古怪的，他想当然地认为，完全可以运行多个不同的模拟器进程，来执行不同的任务，使得每个任务都可以享受内存保护。这种浪漫主义情调让他无比鄙视Apple员工的智商。而事后当笔者使用早期版本的Mac OS X时，发现Linus Torvalds的想法完全是不切实际的。因为这个模拟层本来就要占用不少的内存和CPU，在处理器速度不及今日手机、内存无比精贵的90年代末，跑一堆模拟器进程无异于是和自己过不去。
Steve Jobs考虑到Linus Torvalds是开源软件的领军人物，便继续以开源为话题，动之以情，晓之以理。他告诉Linus Torvalds，我们这个系统做出来后呢，所有的Unix层（非图形界面层），都会开源，所以事实上你加入我们，也是在给开源做贡献啊！而由于在开源圈子混久了，Linus Torvalds对此丝亳不领情，他认为，有谁会想用一个底层是开源而图形界面是不开源的系统呢？所以，像笔者这样的用户被“代表”了。
Mac OS X与Linux分道扬镳
总之，这次会面完全谈崩，两人站在不同的角度去看问题，加上Steve Jobs和Linus Torvalds都是个性鲜明、唯我独尊的人，技术和商业上的考虑都不同，所以会谈中双方简直就是鸡同鸭讲。这次讨论也使得Apple放弃Linux，转而采用FreeBSD技术，并在2001年任命FreeBSD的发起者、领军人物Jordan Hubbard为BSD技术小组的经理，并在后来升为Unix技术总监。至于Apple的内核技术后来走向何方，我们下期再讲。
笔者认为，Apple和Linus Torvarlds的商谈破裂，以今天的眼光来看，是因Linus Torvarlds的自命清高和短视造成的。他不懂得尊重其他开发者的意见，并且不断抬扛。包括后来关于C++的论战。Mac OS X发布后，Linus Torvalds又数次嘲笑Mac的技术落后，并说这些他在当年和Steve Jobs开会时就预料到了。直到最近，他终于有些成熟，对Mac OS X的观点开始缓合，但还是不忘批评Mac的文件系统就是垃圾（事实上，Linux的也没好到哪去，至少Apple还搞过一阵ZFS）。这种性格最终导致在Mac OS X和iOS大行其道的时候，Linus Torvalds连兔子汤都不曾分到。
而事实上这对Apple也是件好事。Apple重要的是利益而不是折腾，即使是开源也是利益驱动。像类似Linux开发组那样自以为是但代码又写得差的开源项目，Apple事后也遇到不少，比如GCC编译器项目组[1]。虽然大把钞票扔进去，在先期能够解决一些问题，但时间长了这群人总和Apple过不去，并以自己在开源世界的地位恫吓之，最终Apple由于受不了这些项目组人员的态度、协议、代码质量，觉得还不如自己造轮子来得方便，因此Apple推动了类似LLVM这样宏伟的项目，并且在短短几年内，使其成为最领先的开源软件技术。这无异于扇了Linux小组、GCC小组一记响亮的耳光。

## Mac OS X 背后的故事（三）Mach之父Avie Tevanian

1975年，美国罗彻斯特大学纽约分校，一组研究员正在做一个名为RIG（Rochester”s Intelligent Gateway）的项目，它由Jerry Feldman主持设计。RIG的目标是给所有本地以及远端的计算设备（比如磁盘、列印机、磁带、绘图机等）提供一组统一的访问方式，其作业系统称为Aleph。为了实现所需要的功能，Aleph的内核主要构建了一个进程交互（Interprocess Communication，IPC）的机制。RIG的各进程，只要设置了目标端口，就可以彼此间发送信息。RIG项目没过几年就被判了死刑，主要是缺少很多有用的功能，比如端口没有保护机制，一次最多只能发送2KB大小的信息（受硬件限制），也没有很好的网络支持等。不过在20世纪70年代，这个系统依然代表着当时作业系统设计的先进水平，比如除了进程交互外，每个进程还有内存保护的功能，这足以让20世纪90年代末都没有做出内存保护技术的Apple公司汗颜。

该项目后来失败了，随后在1979年，RIG的Richard Rashid博士毕业到卡内基-梅隆大学当教授，开始做Accent项目。它是一个网络作业系统，于1981年4月开始活跃开发。受RIG的影响，Accent系统的亮点也在于可以使用IPC，而且解决了很多RIG的不足。比如每个进程有4GB的虚拟内存空间，而且甚至连内核自已都可以被存入缓存页面，内存有先进的更新前拷贝（Copy-on-Write）功能，可以实现进程间大信息的传送等。读者可以把Accent理解为支持虚拟内存技术，并且具有网络透明IPC功能的RIG内核。
但过了几年，开发者们越来越对Accent失去兴趣。在1980年初，很多人觉得多核计算是计算机未来发展的潮流，但Accent内核在设计时并没有考虑到这些问题。而且，随着许多实验室纷纷购置性能更强劲的计算机，这就意味着Accent需要移植到新的目标架构上。此外，Unix正大行其道，不管是在作业系统理论上还是在用户程序上，都成为最为流行的作业系统模式，而Accent并不是一个Unix系统，所以无法享受Unix世界的诸多美好。为了解决这个问题，研究人员决定把所有设计推翻重来，于是就有了一个全新的系统。
在匹兹堡的一个雨天，卡内基-梅隆大学的Avie Tevanian，此系统的最主要开发者，正打着伞和同学们在去吃午饭的路上。他们一边绕着无数的泥塘，一边构思给这个新系统取什么名字好。灵感突来，Avadis Tevanian建议把这个系统叫作Muck，引得同学们哈哈大笑。后来，Richard Rashid和一位意大利同事Dario Giuse说起这玩笑，结果这位同事不经意地把Muck发为Mach，遂把Richard Rashid笑翻，伟大的Mach系统因此得名。
Mach是一个受Accent启发而搞出的Unix兼容系统。那年，Unix已经十六岁，而且依然是作业系统理论与实践开发的主要阵地。Unix内核由于新加入的功能越来越多，变得越来越复杂。而Mach的一个主要目标就是尽量缩减Unix的各项服务，以使内核变得简单可维护。此项目从1984年开始，目标主要是包含完整的多任务支援、良好的硬件移植性，并要把大量服务移出内核作为跑在内核上的服务，以及提供与Unix的兼容性。
Mach使用纯C编写，所以在一定程度上保证了可移植性，这事实上为后面的NeXT向PowerPC移植以及2005年的向Intel移植提供了很重要的前提。而为了缩减内核该管的任务，Mach做得很绝，只提供内存和处理器管理。类似于档案系统、网络、输入输出等功能都作为单个的系统进程，独立执行于内核之上。Mach的开发过程以4.3BSD作为起点，以RIG的Accent作为参考，采纳DEC的虚拟内存设计思路，逐步开发，以新写的代码代替BSD的代码。两年后的1986年，虽然没能把系统服务完全分离于内核之外，但已颇见成效。Mach第一版大功告成，组员发表会议论文，成为操作系统史上里程碑式的经典，引发操作系统业界的“微内核”学潮，如今学习作业系统设计的皆需学习此文，二十五年来被引用一千二百余次。
这篇文章主要讲了两方面内容：IPC和虚拟内存。在IPC方面，Mach把复杂的消息传送机制分为四个独立的清晰概念—任务、线程、端口、信息。任务是拥有一组系统资源的对象，允许线程在其中执行；线程是执行的基本单位，拥有一个任务的上下文，并且共享任务中的资源。
由于该论文的影响力，所以项目得到了OSF（Open Software Foundation）在内的很多投资。当然了，学术和工程永远存在差距，所以即使是最受欢迎的Mach 2.5其实仍然是一个包括大多数BSD服务层的单内核。但包括NeXTSTEP、OSF/1在内的很多操作系统都采用Mach作为其内核技术，原因是广大研究人员依然相信微内核代表着未来。虽然Mach 2.5的效率比传统的Unix系统稍低一些，但研究者们表示情绪淡定，因为Mach支持多处理器系统，可以利用多线程把任务处理得飞快，相比之下其他Unix内核并没有多处理器的完善支援，因此Mach效率稍低完全可以接受。但随着真正把Mach和BSD服务完全脱离的Mach 3微内核面世，研究人员们的情绪就再也淡定不起来了。因为服务和内核分离后，任务间的IPC数量暴涨，一个简单的Unix系统调用要涉及到十多个开端口、设权限、发送、收取消息的操作，哪怕是使用数年后的1997年的硬件，跑一个系统调用密集的程序，Mach的效率要比一般的Unix系统慢50%，而且根本没有什么好方法来解决这个问题。
所以Mach 3出来后，虽有少数微内核信徒继续执著地改进Mach，或者开始其他微内核比如L4的研究。但学术界对Mach的兴趣大减，因而Mach 3也成为最后一版。项目解散后，Richard Rashid去了微软研究院。
再说我们的主角Avie Tevanian，他1987年博士毕业去了NeXT。这家公司刚刚由Steve Jobs成立两年，这两年Steve Jobs啥正经事都没干，只是花了十万美元雇Paul Rand设计了一个公司商标。直到Avie Tevanian加入后，这个公司才开始干实事。1987年公司确认要开发一个面向研究人员使用的计算机工作站，于是软硬件的开发工作紧锣密鼓地展开。硬件组由领导过Apple Lisa的Rich Page原班人马负责，而软件则由Avie Tevanian负责，计划开发一个有图形界面的操作系统NeXTSTEP。由于Avie Tevanian是Mach主要的开发者，自然NeXTSTEP就基于Mach了。1988年10月12日，NeXT发布预览版（0.8版），并于1989年9月18日发布1.0版（注：http://en.wikipedia.org/wiki/NeXTSTEP）。
作为NeXTSTEP系统的内核，NeXT分支的Mach经历了不少变化。NeXTSTEP 0.8主要使用Mach 2.0版，而稍后的NeXTSTEP 1.0版主要基于Mach 2.5版，包含一个自己定制的当时最新的4.3BSD服务层。从3.1版开始，NeXT分支的Mach还包括一个全新的设备驱动框架, 名为Driver Kit，仅供x86系列的硬件使用。和Mach以及BSD代码不同，Driver Kit是使用Objective-C写的。为什么是一个面向对象的语言呢？看NeXTSTEP 3.3的DriverKit文档。读者大概就会发现，NeXTSTEP把所有硬件设备理解为对象，而我们知道，对象之间有继承关系，比如，磁盘（IODisk物件）属于输入输出设备（IODevice物件）的子物件，而磁盘（IODisk）本身又是逻辑磁盘（IOLogicalDisk）的父物件。硬件的初始化对应于每个物件的初始化（init方法），硬件又有读、写，所以可以用getter/setter的方法。因此，DriverKit是一个非常有特色的实现。而且由于Objective-C的效率很高，依赖很少（Objective-C程序可以直接被编译器翻译成等价的C语言程序并编译，而Objective-C的运行库libobjc也以高效著称），所以也是编写驱动的良好选择。几年后的IOKit其实就是个DriverKit的翻版。
这时，NeXTSTEP操作系统大获成功，风险投资商们纷纷购买，但硬件却始终卖不出去（注：Aaron Hillegass《Cocoa Programming for Mac OS X》前言），所以NeXT砍掉了硬件部门专做软件，更是使NeXTSTEP发展到了巅峰时期，同时支持68K、x86、PA-RISC和SPARC等硬件，但颇有意味的是它就是不支持PowerPC架构。它可以同时产生一个包含所有架构可执行码的二进制文件，来使开发的程序在所有平台上执行。这个功能也影响了后来Mac OS X的技术。Mac OS X 10.4时代有两件跨时代意义的事情，一件是Apple搞出了64位的Power Mac，开发者可以发布一个包含64位和32位程序的单一可执行文件，而无需让用户去区分；另一件是和Intel合作。Apple正式发表了Universal Binary技术，可以一个Mach-O文件同时包含Intel和PowerPC的指令。这非常贴心的设计（要知道，大多数电脑用户根本不知道Intel、PowerPC、64位、32位等技术）就是来自于Mach的技术。
NeXTSTEP 3.3后，NeXTSTEP因为NeXT和Sun的合作改名为OPENSTEP，1996年发布4.0版，到1997年2月4日，NeXT被Apple收购之前，期间内核改进除源码同步到Mach 3.0版外不明，而且出于不知道的原因，我手头的OPENSTEP正式版光盘中，居然找不到DriverKit的发布说明和编程文档，故不作详述。不过这段时间，Apple的活动值得好好一说。之前在《Linus Torvalds的短视》中，我们曾提到，1996年，Apple和OSF曾经合作，把Mach移到PowerPC Mac上，再把Linux作为单一的服务跑在Mach上，这个项目叫做MkLinux。在1996年发布基于Mach 3.0和Linux 1.3的预览版，并更新到2002年结束其历史使命，对Mach在PowerPC的移植性上做出了重要贡献。这个PowerPC版的Mach被叫作osfmk分支，也正是现在Mac OS X中用的分支。当然了，NeXT被合并后做了大量修改。
Apple收购NeXT后，Mach被确定作为未来的操作系统核心。Avie Tevanian被选为软件开发部的总裁。合并所有项目的号角吹响后，上层的OpenStep API和老版Mac OS的部件开始合并，而Mach也经历重大变化。主要是一方面，Mach使用了osfmk分支，但依然包含4.3BSD服务；另一方面，DriverKit被IOKit取代。这是Apple走得很被动的一步。因为当时外界普遍对Objective-C不看好，逼着Apple走老版Mac OS  API的老路。而Apple自己对Objective-C也很不自信，甚至想索性换用Java了事（我们以后会谈及这段不自信的历史）。所以IOKit是一个C 的驱动架构，来符合大众口味。这些改变最早在Rhapsody中出现（我们以后也会有一期Rhapsody的专题）。但由于C 是门很恐怖的语言，所以Apple又把C 给阉割了，去掉了多重继承、模板、运行时动态以及异常，让开发者使用这种对于Objective-C来说换汤不换药的Clean C 来做驱动。但公正地说，IOKit对于Driver Kit是有不少改进的，比如IOKit可以写在用户空间跑的驱动（虽然大多仍是跑在内核空间上的），因而驱动挂了而系统不会挂。另外IOKit考虑到了计算机发展的趋势，所以在电源管理、即插即用、动态加载上做得更好。
但各位也知道，C 程序得用专门的运行库才能跑，所以Mach中又加入了一个叫作libkern的库负责C 相关的功能，同时，还有一个libsa的库提供一些类似二分查找、排序等基本算法之类的功能。最后和硬件相关的还有一个叫作pexpert（Platform Expert）的库，负责收集硬件设备列表、检测机器种类（比如处理器速度等）、解析启动参数等杂活。
至此，Mac OS X的内核完全形成，形成BSD、IOKit、Mach osfmk三足鼎立的态势，并有pexpert、libkern、libsa作为基础。Apple称它的内核杰作为XNU。其代码开源，请读者移步http://www.opensource.apple.com/source/xnu/xnu-123.5/，每个部分的代码都独立存放在一个文件夹中，条理清晰，不妨一读。
由于4.3BSD已是过眼烟云，Apple后来投入大量资源扶持FreeBSD开发。2001年，Apple将FreeBSD的发起者、领军人物Jordan Hubbard收入麾下，并在Mac OS X 10.3时基本同步到FreeBSD 5的代码（注：http://osxbook.com/book/bonus/ancient/whatismacosx/arch_xnu.html）。
另外，Apple 的开发也同时反馈到FreeBSD小组，包括FreeBSD 6.2 内核引入的 AUDIT (man audit 或参见http://manpages.unixforum.co.uk/man-pages/unix/freebsd-6.2/4/audit-man-page.html)，后来 FreeBSD 8引入的 libdispatch （http://wiki.freebsd.org/GCD, 在Apple这项技术叫Grand Central Dispatch，是Mac OS X 10.6 主推的新功能，FreeBSD基本在 Mac OS X 10.6 上市的同时就拥有这项最新技术），以及 FreeBSD-CURRENT 中的 LLVM-Clang，全是Apple的手笔。从 1999 年开始，FreeBSD 源码仓库可以搜索到 Apple 提供的大量的补丁以及新功能。
Mac OS X早期版本不太稳定，所以会内核崩溃。10.0版本会直接像Linux或者BSD那样打出回溯信息，很不美观，所以Apple在10.2版本开始设计了一个多国语言的图片告诉用户你的内核崩溃了，以让内核崩得看起来更优雅一点。由于包含四国语言，被国内用户戏称为“四国”（注：优雅的图片见http://support.apple.com/kb/ht1392），这是XNU的Mach osfmk部分的功能。但从10.3~10.4版本开始，系统越发稳定，正常使用已很少见到内核崩溃。而且，内核提供的服务也越来越多，使得Mac OS X成为一个完善的系统。
21世纪XNU架构方面的最重大改动是支持了PPC64（10.4版本时代）、x86架构（其实本来也一直支持的，以后讲Apple的Intel迁移时详谈）、x86_64（64位支持是苹果长年努力逐步展开的。10.4时代32位内核支持载入64位的用户程序，10.5系统提供64位的Cocoa框架，但系统 大部分程序都是32位的，10.6时代内核支持以64位模式启动，但在不少硬件上这是非默认的方式，但系统大量程序已被改写并编译为64位的二进制程序，10.7时代内核默认以64位模式启动。）和ARM架构（iPhone和iPad使用XNU内核）等多个新架构。
而其中ARM架构的支持别具意义。但2006年5月31日，功成名就的Avie Tevanian离开Apple另谋发展，此时，离Apple的iPhone奇迹发生，只有不到一年时间。

## Mac OS X 背后的故事（四）——政客的跨界

《Mac OS X背后的故事》系列文章将为大家介绍Mac OS X的发行版本、技术历史、相关人物等内容。本文是系列连载的第四篇。
2000年，美国总统大选，由于选票设计问题，时任美国副总统的 Al Gore 败北。2000年12月13日，在一番重新计票的大折腾不起作用后，曾经意气风发的 Al Gore 拖着疲惫的身子，走上讲台，发表了认输讲话（参见Al Gore《2000 Presidential Concession Speech》），从此退出政坛。一般国家领导人的退政生活其往往松愉快，出出日记，学用哲学，或者像多才多艺的李岚清不但去各地推广古典音乐，更是玩起了篆刻（参见《南方周末》2006年05月11日《老常委的卸任生活》），克林顿先生都成立个基金会来帮助社会预防和治疗爱滋。 Al Gore也没闲着，他找到了让他感兴趣的去处——Apple总部，并成为董事之一。
#### Mac OS X和Al Gore的双赢
2003年5月19日，Apple的启示中罕见性地登出了《前总统Al Gore加入 Apple 董事会》的快讯。文中提到，Al Gore总统是一个正宗果粉，他一直用Mac计算机，而且还会用Final Cut Pro来编辑他的视频。Al Gore也不掩饰他对Apple技术的热爱，他表示对Mac OS X的开发极感兴趣，并且也对Apple在开放源代码运动中的贡献喜闻乐见。他虚心地说，想在这个让Apple起死回生的董事会好好观摩并学习。

苹果公司的CEO Steve Jobs表示Al Gore曾经管理过世界最大的组织——美国政府，期间显示出的经验和智慧对苹果公司是笔巨大的财富。Al Gore将成为出色的董事会主席，苹果将以他把苹果公司作为职业生涯的开始为荣。
这之后，Al Gore在Apple内部的决策究竟起了什么作用，和Mac OS X的开发有何关联，在正式的渠道很少有史料，但是他后来的各种公开活动，却给Mac OS X的技术做足了广告， 而且很多证据表明，他正是使Apple从被绿色人士攻击的众矢之的的状态，成为业界注重电子产品环保领头羊的主要推手。
Al Gore重新进入普通人的视野是在2006年，他推出了自己参与制作和演出的纪录片《An Inconvenient Truth》（《难以忽视的真相》）和同名书籍。这部长达94分钟的影片，在西方国家引起了广大的回响，以Al Gore的一场演讲和人生的回忆作为两条主线，详细、科普地向民众介绍了全球变暖问题的科学证据及美国政府掩盖问题的真相。该片以发人深省的立意、详尽的科学数据、平实的讲演风格，加上苹果高超的技术，而获得了广泛的好评并一举获得年度奥斯卡最佳纪录片奖，使得这位美国前副总统摇身一变，成为好莱坞明星。
为什么单单一场简单的讲话，就能做出一部电影，还能得到奥斯卡这样学院艺术奖的亲睐？是因为讲话内容无懈可击么？事后有很多科学家站出来表示，虽然影片内容有积极的意义，但其实也有很多被夸大的科学数据、假设和结论。试思索，该片之所以成功，甚至成为诸多演讲培训机构的重要分析案例，除了数据、观点、论述外，还有以下几个原因。
首先，这场演讲由苹果主导的技术和艺术的设计。Al Gore向来以说不清想表达的内容而著称。他经常因为讲得过于专业或者缺乏好的表述方法以致于民众完全不懂他在讲些什么。他的早期讲话用现在的眼光看就是个少将体，比如“互联网…网…我…这个…那个…那个…怎么说呢…我想这个…这…这…这…我啊…我啊…就是说…互联网是我发明的！”因此作为苹果展现公司软实力的重要机会，苹果非常重视这场讲话，请公司的图形设计小组带领完成各种所需设计，苹果甚至特地请来了专业的设计公司Duarte来进行讲稿和讲话内容的安排。因此，不管是内容安排、图形设计还是技术支持，Al Gore都有强有力的后盾，他们能够帮助Al Gore完成任何想达到的目标。不论是FinalCut还是Keynote，一旦缺少任何Al Gore想要的功能，Apple都可以给他开小灶实现。在片末的走马灯字幕中，有大量Apple的 Keynote组、Final Cut组和图形设计组的员工名字，以示鸣谢。
其次，上面这些资源的相互合作，也使得Al Gore的这场讲话的讲稿被精心制作，体现了精心设计的电子稿演讲所能达到的最高成就。苹果公司向来重视演讲，也是各大企业中最会通过演讲来营销产品的公司。每年的MacWorld和WWDC的 Steve Jobs 讲话都会吸引百万人在计算机前观看。每场讲话都好戏连连，台下的观众的欢呼和掌声不亚于著名歌星的演唱会。这种风格显然给Al Gore的讲话风格带来很大的影响。在影片中，观众看不到一个传统的bulletpoint（PowerPoint用户常爱使用的表示讲话结构的方法），取而代之的是高清的照片、视频，来展现环境的严峻性。观众不再会为枯燥无味的技术词语而搞得昏昏欲睡，因为屏幕上的一切都是如此真实，各种科学现象由动画效果配合，使其浅显易懂。另外，所有的数据、图表都精心使用软件制作，使其一目了然，表现准确而美观大方，而且Al Gore时而还会玩些小噱头，比如讲到现在的温室气体浓度是多么高时，他甚至爬上工作人员为他准备的升降机，升到舞台顶端，来告诉观众，数据已经突破图表的顶端了。现在距笔者观赏完这部影片，已经五年过去了，但影片中的灾难场景、冰川融化的影片段落、海平面上升的计算机模拟、二氧化碳浓度的数据图表，至今都记得一清二楚，足以见得其表现力是何等深入人心。甚至有人在调侃他在2000年的竞选演说是怎么回事？难道就是缺少了这些科技元素？
最后，Mac OS X的各项技术也是这部片子的重要保证。Duarte 公司的 Ted Boda表示（该幻灯片的设计师之一），Mac OS X系统本身的反锯齿功能把文字、图片、矢量图标表现得栩栩如生，使得幻灯片充满美感。QuickTime技术作为Mac OS X的一块重要基石，又使得Keynote不需任何插件就能引入任何图片和影像，所以类似使用Illustrator、Photoshop、AfterEffects等软件做出的图片、影像或动昼，不需要任何转换过程就能直接拖到Keynote中。哪怕1920×1080的高清视频，都可以轻松插入，流畅播放。他们组根本想象不出在Windows上使用PowerPoint会成什么样子。
可以说，没有Mac OS X，就没有这部电影。而实际上这部电影的作用远胜过任何一部Apple公司的广告。片中Al Gore时时拿着PowerBook的笔记本，在办公室用Safari查网页，字体渲染真实而美观，甚至在车上都不忘打开笔记本用Keynote做几张幻灯片，就更不用说电影中Keynote幻灯片曾经迷倒多少Windows用户了。向笔者推荐这部电影的好朋友了解到这些全是Apple技术的功劳时，拥有一台Mac就成为其人生梦想。
#### 环保卫士的Apple之路
作为环保人士，Al Gore对Apple的策略的影响也不容忽视。Apple向来被各环保组织长期批评，即使Apple长年不断地改进这方面问题，但绿色人士依然不买帐。哪怕在稍后的2007年，也仍有包括GreenPeace在内的七十多个组织联名写信给Al Gore，敦促Apple更重视环境问题，信中指责Apple仍在大量使用PVC和BFRs等对环境有害的材料，也不注重对自家产品的回收。由于Al Gore是Apple董事会成员，使得这个问题受到了Apple的广泛关注。Apple在07年后史无前例地迈开大步，大力推广环保计划（要求全世界的IT制造商们逐步弃用PVC等有毒的化学用品进行生产），让Apple一跃成为注重电子产品环境保护问题的领头羊。
从制造材料上，2007年8月发布的iMac成为分水岭。这款产品的设计主要使用可完全被回收的玻璃屏和铝外框，减小了塑料等不环保物质的使用，此后苹果一发不可收拾，把这项革命进行到底，从手机到笔记本，都全番设计。2008年的MacBook Air引出的Unibody技术是这场革命的代表产品，不但在外观上还是工程上做到极致，在环保上更是让各绿色组织无可挑剔。
在造势上，Apple现在每项主要产品的都有“环境”的标签页，从制造、运输、耗电、回收等性能情况分产品详细列出。Apple甚至在包装上都动足脑筋，尽量减少每个产品的包装，使得同一架飞机可以运输更多的产品，从而在运输相同数量产品的情况下减少飞机温室气体的总排放量。
Mac OS X的各项节电功能的开发更是不用说了。休眠、调整空闲时的屏幕亮度、硬盘转速等常规功能自然越做越好。而系统的多项技术能使程序更优地分配使用中央处理器和显示卡。甚至系统还能在用户打字时，每两键之间的空隙减少处理器的占用从而节省击键之间的功耗，这使得 Mac OS X不但更节约能源，笔记本的电池使用时间也不断提高。而这一切的变化，和Al Gore似乎都有着千丝万缕的联系。
由于《An Inconvenient Truth》中的讲话让Al Gore的观点深入人心，同时也对美国政府在京都议定的决策产生重大的压力，挪威诺贝尔委员会决定把2007年的诺贝尔和平奖颁给了Al Gore，以表彰其在全球环境问题方面的努力，同时苹果的主页上全版刊发新闻，以示祝贺。贺词如下：
Al has put his heart and soul, and much of his life during the past several years, into alerting and educating us all on the climate crisis. We are bursting with pride for Al and this historic recognition of his global contributions. (Al Gore在过去几年殚心积虑，全身心地投入对公众关于气候危机的警示和教育中。我们为他这次所得的荣誉和他全球性贡献的历史性承认感到无比自豪。）
或许，由于Al Gore在计算机领域的一贯低调（他也是Google的高级顾问），他在这些企业的工作很少被报道出来，但是他在政界的跨界身份是显而易见的。Al Gore在他的人生道路将何去何从，我们不得而知，但是从各种媒体信息的披露可以看出，Al Gore对计算机事业的热衷，对环保问题的投入，可能是美国历任领导人中最突出的。

## Mac OS X 背后的故事（五）Jean-Marie Hullot的Interface Builder神话
Interface Builder，是用于苹果公司Mac OS X操作系统的软件开发程序，Xcode套件的一部分，于1988年创立。它的创造者Jean-Marie Hullot自称是“一个热爱旅行、充满激情的摄影师”，本篇分享Hullot热爱技术的那一面——创造Interface Builder的过程。
因势而动
1981年， Jean-Marie Hullot拿到巴黎第十一大学的计算机科学博士资格后，开始了法国国家信息与自动化研究所（INRIA）的研究生活。

Jean-Marie Hullot的名字似乎不为大众所熟知，但他设计的Interface Builder 却深入人心，创造了一个个软件神话。
20世纪70年代初，正是面向对象程序设计开始走上历史舞台的时期。许多现代计算机技术的诞生地Xerox PARC（施乐帕洛阿尔托研究中心）的Alan Kay、Dan Ingalls、Ted Kaehler 、Adele Goldberg等人，从1969年开始研发一款面向对象的程序语言Smalltalk，并于1980年正式公布。这是一个完整地实现面向对象范型的编程套件，包含了一种面向对象的程序设计语言、一种程序设计库和一个应用开发环境（ADE）。
虽然当时的机器跑得巨慢无比，但Smalltalk先进的思想对其他众多的程序设计语言（Objective-C、Actor、Java和 Ruby）的产生起到了极大的推动作用，对计算机工业界的发展产生了非常深远的影响。我们将会在今后介绍Objective-C时，详细介绍Smalltalk及其对Objective-C的影响，这里先一笔带过。
Smalltalk的发布在业界一石激起千层浪，也给Jean-Marie Hullot幼小的心灵带来了巨大的震撼。他立即明白了面向对象思想所代表的先进生产力，一定会改变今后数十年的程序设计流程，他毫不犹豫地成为面向对象编程模式的早期粉丝。
SOS的助力
那时，Jean-Marie Hullot使用早期的Macintosh计算机进行开发。不过他很快就和其他开发者一样，发现虽然Mac的用户界面做得不错，但开发程序实在是太糟糕了。他说：“当Macintosh被发明出来时，计算机和先前就大不一样了，你至少需要花60%~70%的时间在用户界面部分的代码上。”在Macintosh被发明之前，用户界面是相当简单的，只需要在命令行下面打一串字符，计算机就会回应出一行行的信息。所以在那个时代，开发者完全不需要专注于用户界面。而Mac一经发布，随之而来的众多的窗口和菜单，让整个世界都不一样了。虽然对于使用最终产品的用户而言是简单方便的，但对于码工来说简直是个噩梦。每次他们需要一个窗口或者菜单，都要从零开始构建。
聪明的Hullot开始动脑筋改进Mac编写用户程序难的现状。他开发了一个程序，有点像现在Windows系统中的“画板”。一侧的工具条，是类似菜单这样的大量可重用的对象；而另一侧，则是程序员想构建的用户程序界面。只要把工具条上的工具拖放到程序界面中，那么类似“打开”、“打印”等相关的功能，就可以被添加到用户界面中。事实上，这个程序，是最早的一批能通过鼠标把控件拖入界面设计窗口实现相应功能的商业程序，是用户界面设计软件的先驱。
这个跨时代的发明被称作SOS，用Lisp语言编写【注：What are we going to called this thing中认为此时就是Interface Builder，但据The NeXTonian等多处资料表明，在Steve Jobs见到以前，该程序名为SOS】。当时，ExperTelligence开发了一种叫做ExperLisp的方言，SOS即用此语言写成【注：http://en.wikipedia.org/wiki/Interface_Builder】。
此时Hullot忽然意识到，他设计的东西事实上很强大，其重要性简直可以和Smalltalk这样的发明相比——Smalltalk让开发者尝到了面向对象语言的甜头，而SOS则是直接把对象放到了开发者手边。有了这么拽的东西，Hullot意识到如果他只在研究所窝着，那只能让十几个人享受这一成果，而如果他跳槽，把这个工具公开，那对天下的码工来说可是大福音。
诞生之源
经过不断努力，Hullot找到了一个值得推销自己发明的好地方——剑桥的苹果大学联盟（Apple University Consortium）。这个苹果和大学合作的组织看到Hullot的创作后反响很好，就推荐他去见Jean-Louis Gassee。 Jean-Louis Gassee是个法国人，时任苹果开发研究院主任，见到SOS后也认为这是个好东西，便说服他去美国闯一闯。经过几次的鼓励和推荐，加上美国对Hullot来说又不陌生，于是他就买了机票跳上飞机就奔赴美国。
不过当Jean-Marie Hullot来到美国加州苹果总部时，他却认为这不是一个工作的好地方——苹果已经是一个很庞大的企业，很难再有所创新发展。他最终决定不留在那儿，转而在美国寻找一个能把这个产品卖出去的人。四处推销之后，找到他用来写SOS的Lisp解释器的生产商，就是刚才提到的位于Santa Barbara的软件公司 ExperTelligence。
事实上，当时的ExperTelligence正在寻找合作商卖自已的Lisp，而Hullot也在找合作商卖自已的 SOS，两者一拍即合，随即打电话给 NeXT，共同推销自家的产品。
NeXT在Palo Alto总部的产品市场部人员接待了Jean-Marie Hullot和两位来自ExperTelligence的员工，被SOS的理念镇住，遂打电话请Steve Jobs下来看。Jean-Marie Hullot像复读机一样又把自己的大作秀了一遍。老谋深算的Steve Jobs事实上早就看中了SOS，但他对ExperTelligence的Lisp一点兴趣都没有。所以他装作对这场演示毫无兴致【注：这有很多引用该文的翻译译错，原文说nonplussed，字面意思为惊异，但在美国非正式表述中，此字表毫无兴致】，挥挥手就把这三个人打发走了。
但当他们一行人走到停车场时，Steve Jobs让他手下把Hullot追了回来，当他只身回到NeXT总部时，发现Steve Jobs正恭敬地等着他。
“我想要你计算机上那个程序”【注：http://rixstep.com/2/0/people/】，Steve Jobs说道：“你大概什么时候能开始给我们工作？”
Hullot回答说自己翌日就要离开去度假。
“好吧，我两周后给你打电话，”Steve Jobs说。
“不行，老乔”，Hullot表示：“我不游美国，我可要环游欧洲，你七个礼拜后再打给我吧。”
Steve Jobs虽然一骨子傲气，但他明白一个简单的道理：21世纪最缺的是什么——是人才！即使Jean-Marie Hullot玩起了大牌，这电话自然还是要打的。Hullot刚一度完假回来，Steve Jobs的电话就如期而至。
如此三顾茅庐般的热情，把Jean-Marie Hullot感动得第二天就登上了去美国的飞机。合约签了半年，但实际上他最终在NeXT整整待了十年。在NeXT工作期间，他使用Objective-C和NeXTSTEP框架重写了SOS，命名为Interface Builder。由此，Interface Builder成为NeXT集成开发环境 Project Builder标准套件之一。
进阶与探索
Interface Builder和SOS一样，提供了一个工具箱，包含一系列用户控件对象。工具箱并不是官方定死的，而是可以任意扩展的，比如如果用户想使用类似Safari中的toolbar，而这不是官方提供的，则下载第三方的PSMTabBar即可实现，甚至连Cappuccino这样的网页框架也可以用Interface Builder来完成设计。开发者只要把控件比如菜单和文本框拖入项目文件就能完成用户界面设计，节省了几乎所有和控件放置有关的代码。
开发者拖拽鼠标，将控件可提供的动作（IBAction）和另一个对象的接口（IBOutlet）连在一起， 则建立了一个绑定。这样，一旦动作被激发（比如用户点了按钮），那接口中相应的方法则会被执行。所以，大量对象关联的代码也能被省去。
有了这样的模式后，Interface Builder和Cocoa可以比后来出现的Microsoft Visual Studio或Qt Designer等软件走得更远——只要是对象，Interface Builder就能够操控它们，不需要一定是一个界面的控件。比如，数据库的数据源、队列等，都可以在Interface Builder中连接起来，于是很多原本需要上千行的复杂应用（比如用来显示、修改企业中职工姓名、部门、电话、地址、头像等信息SQL数据库的用户界面程序），数分钟内就可以写完，不用一行代码。不信？让1992年的Steve Jobs亲自做给你看【注：http://www.youtube.com/watch?v=j02b8Fuz73A， 第23分钟～第29分钟】。
NeXT被Apple收购后，苹果把下一代操作系统建立在NeXTSTEP的基础上。Objective-C和Cocoa被作为主要框架，而Interface Builder和Project Builder也因此受到重用。就官方的工具箱而言，支持Objective-C/Cocoa、Carbon的HIToolbox和WebObject。
2008年3月27日，苹果发布首个iPhone SDK，设计Cocoa Touch界面的，也正是Interface Builder。可以说，Interface Builder一直随着公司产品的发展而不断拓新。
Jean-Marie Hullot是在NeXT被收购时进入苹果的。Steve Jobs令他率领在法国的一个小团队，秘密为Mac OS X 10.2开发一个办公软件。以往这样量级的程序，都是由苹果加州总部的大班人马完成。而这次，为了向世人表明他的Interface Builder有多强大，iCal横空出世，展示复杂的界面元素（日历、可拖拽的任务、五花八门的分类）和诸多功能（网络同步、Apple Script脚本控制）可以用相当快速的时间内开发出来【注：http://www.appleinsider.com/articles/07/10/17/road_to_mac_os_x_leopard_ical_3_0.html&page=2】。
最后，在iCal小组打完酱油的Jean-Marie Hullot荣升苹果软件开发部首席技术官。
Project Builder在Mac OS X 10.3时被重命名为现在大家所熟知的 Xcode。Xcode 3以前，Interface Builder使用一种名为nib格式的二进制文件格式。不过由于nib不能用肉眼读，也不方便使用版本管理工具来管理，所以Xcode 3开始新加入一种名为xib的文本文件格式，最后再在项目编译阶段输出为nib格式。和产生静态界面布局代码的工具（如MSVC、QtDesigner、 Delphi等类似的软件）很不同，nib是不被转译成相应Objective-C代码的。用户程序执行时，nib文件被读入，解包，并且唤醒【注：awake，即载入 nib 会自动调用程序中awakeFromNib方法】，所以nib文件是在运行时动态加载的。
长期以来，Xcode环境和Interface Builder是两个独立但相互工作的程序。而2010年释出的Xcode 4预览版中，Xcode和Interface Builder合二为一，成为一个一体化的编程环境。所以现在，开发者甚至可以只用鼠标在用户界面和代码间来回拖拽就能完成，这样一来Interface Builder对用户代码的解释也比先前更正确。比早期分离的程序使用起来确实方便很多。
当然，一个负面的影响是，这样用一体化集成开发环境写程序，往往会发现屏幕空间是不够的，所以像我这样用11寸Air或者13寸Macbook Pro的人，出去打招呼都不好意思说自己是做Mac开发的。
下一个海阔天空
在而后的岁月里，Interface Builder创造了一个又一个应用软件神话，小到官方教程中的汇率计算器，大到苹果所有的家用、专业软件，都由Interface Builder完成。
在风起云涌的1989年，欧洲核子研究组织（CERN）工作的科学家Emilio Pagiola忽悠经费，买来研究所的第一台NeXT计算机——当时NeXT计算机在CERN可是个新鲜事物——那里的科学家们纷纷前来把玩，普通青年发现里面有全本的韦氏词典，并可自动检查用户输入的拼写错误，技术青年发现它跑的是Unix系统，还有一个可读写的光驱，文艺青年更是发现里面居然预装了莎翁全集。不过毕竟像Emilio Pagiola这样忽悠巨款买NeXT机器的青年不多，所以大家围观完了，也就回去该干嘛干嘛了。
但Tim Berners-Lee和别人不一样，他不仅围观了那台计算机，还看到了Jean-Marie Hullot设计的 Interface Builder，研究了Objective-C，发现了面向对象编程范式开发环境的最高成就。这情景让他心中漾起了巨大的波澜，最终化为激情澎湃的投入，汇成了一行行面向对象的代码，一泻千里，奔向未来。
一年后，世界首个 HTTP 服务在CERN的NeXT计算机运行起来，而使用Objective-C和Interface Builder 所编写的超文本语言编辑器兼浏览器同步发行。他给这个主从式架构起了个好听的名字——World Wide Web（万维网）。

## Mac OS X 背后的故事（六）Cordell Ratzlaff 引发的 Aqua 革命（上）
Aqua是Mac OS X Public Beta全新用户界面的名字，英文中为水的词根，寓意以水为灵感，精心设计。Steve Jobs曾介绍说，Aqua的设计是如此之美好，初次见它甚至有想亲吻的冲动。本篇Cordell Ratzlaff 引发的 Aqua 革命（上）介绍的是Aqua的起源和来历，在下篇中，我们将展示Aqua的具体设计过程。
“Mac OS的图形界面就是你们那么业余的人设计的吗？”Steve Jobs开门见山地问。

包括Cordell Ratzlaff在内的设计师们怯怯地点头称是。“你们就是一群白痴！”Steve Jobs骂道。
这个场景发生在Steve Jobs回归不久的图形界面组组会上，前文提到的骂人的话，是他送给图形界面设计组的见面礼。【注：参见http://www.cultofmac.com/how-mac-os-x-came-to-be-exclusive-10th-anniversary-story/87889，How Mac OS X Came To Be，Leander Kahney】
不进则退的局面
Mac OS曾是图形界面设计的先驱。
从System 1开始，Mac就打破了字符终端的模式，使用图形界面和用户交互设计。但自System 1到System 7，10年过去了，界面却始终没有显著的变化。设计组一直认为，为尊重用户的习惯，定下的规矩不要轻易改动。但同时，Microsoft的变化可以说是天翻地覆，从黑屏的DOS，到全屏幕的Windows 1，再到成熟的Windows 3，最后演变到奠定当今Windows界面基础的炫丽多彩的Windows 95。用当时的眼光来看，这个变化是相当惊人的。由于因循守旧，Mac OS在界面设计上从领先掉到了最后。旧的界面原语，一成不变的界面风格，让Mac OS的图形界面在Windows前显得黯然无光。【注：参见http://vimeo.com/21742166】
于是，在图形界面组的组会上，Steve Jobs 抨击了老Mac OS界面的各种不是——几乎所有的地方都被骂了一遍。众矢之的是各种打开窗口和文件夹的方式。在Mac OS中有至少8种打开窗口和访问文件夹的方式，如弹出菜单、下拉菜单、DragStrip、Launcher、Finder等不同的程序。
Cordell Ratzlaff作为主管，他一开始担心是不是会被Steve Jobs炒掉（传闻说Steve Jobs刚进入苹果时最爱炒人，经常会发生一些“神奇”的情况，比如有员工和他一同进了电梯，等一同出电梯时，该员工已被炒掉）。不过批评大会进行到第20分钟时，Cordell Ratzlaff转为淡定，因为他意识到如果Steve Jobs要炒他，不用废那么多话，早就可以动手了。
其实Cardell Ratzlaff是Apple内部较早意识到小组设计不思进取的人之一。他意识到苹果有三个重要的设计问题【注：参见Designing Interactions 第二章My PC 附录访谈】。第一、Apple的很多界面语言不明确。例如，在老Mac OS中，删除文件的动作是把文件图标拖到废纸篓里，但当磁盘和光盘弹出时，居然也是把图标拖到废纸篓里。第二、老Mac OS不会对问题进行变通，如果有几个图标同时显示，窗口还容易操作，但如果有几十个图标或窗口，以相同的方式显示出来，那么在繁杂的页面中找寻所需内容，对使用者则是巨大的挑战。第三、Mac OS的界面过于古板，看上去还是停留在Windows 3.0阶段。总之，当时的Mac OS已经不能代表先进的生产力，也不能代表科技的前进方向，更不能让广大用户得到更多的利益。在Cardell Ratzlaff看来， Mac OS的界面面临不进则退的重大困局，非改不可。
Cordell Ratzlaff的试水
收购NeXT以后，Apple开始考虑如何把NeXTSTEP作业系统变为下一代的Apple操作系统，但界面设计组的倦怠又浮出水面。设计组认为，这是一个浩大的工程，所以他们决定照着Mac OS 8的样子改NeXTSTEP的代码，把NeXTSTEP改成System 8的样子。这并不困难，组里只需一个人就能完成这项任务，这人的工作极其无聊——像小孩子描红模，把新界面的样子临摹得和老界面一模一样。事实上，当Apple 释出Rhapsody和Mac OS X Server初版时，经典Mac OS的界面已经被学得惟妙惟肖了。
Cordell Ratzlaff认为这种混搭，是一个极其让苹果丢颜面的事情。所以，除了那个搞山寨的人以外，他召集其他人做新界面设计的图样。而由于NeXTSTEP具有强大的图形处理和动画能力，因此很多新的图样是在新系统上完成的。

Apple将“What's not a computer!”（看起来不是电脑的电脑）的 概念应用在硬件外观上，设计出具有浪漫主义气质，半透明“果冻” 式且具有艺术美感的iMac，这成了Aqua设计灵感的来源
20世纪90年代初，Apple和Microsoft的操作系统都素面朝天，色调简单，统一的矩形窗口。到1997~1998年，Apple的硬件外观设计取得重大进展：由后来成为金牌设计师的 Jonathan Ive领衔，设计出具有浪漫主义气质、五彩斑澜的、半透明外壳、具有曲线美感的iMac，这个设计成为Cordell Ratzlaff和他的同事们设计的灵感，他们马上就作出了一个全新的界面图样来。【注：参见http://en.wikipedia.org/wiki/IMac_G3】
与此同时，Cordell Ratzlaff 着手解决前文提到的三个设计问题。第一、他提出了一个叫“实时状态”的概念。当用户拖动文件时，废纸保持原样，而如果拖动的是磁盘，那废纸篓的图标变成“弹出”的图标。第二、窗口的问题统一采用动画加以解决。比如窗口的最小化和还原都配有动画，告诉用户窗口的来去方向。当Dock项目有所增减时，项目长度和元素也会随之改变。第三、Mac OS一改死板面孔，呈现多彩的、小清新的图形界面，所有尖锐的直角都被打磨成圆弧，并且有像iMac外壳一样半透明的菜单。当时有评论指责Apple的设计太卡通缺乏权威感，其变化之大可见一斑。【注：参见http://www.aresluna.org/attached/files/usability/papers/onethousandsquarepixelsofcanvas.pdf，One thousand square pixels of canvas On evolution of icons in graphical interfaces by Marcin Wichary 第五页】
Cocoa之父Bertrand Serlet，作为Cordell Ratzlaff的上司，对新界面很满意。但当时，他们认为这个新界面实现起来难度很大，既没有时间也没有资源把这个想法在Mac OS X中付诸实现。于是先前那位孤独的照葫芦画瓢的设计者只好继续工作。
Aqua只是个设想（PS出来的图样＋模拟出来的视频），还不是能用的代码。
Steve Jobs的怒火和Aqua的源头
几个月以后，Apple举办了一个所有开发小组参加的长达两天的汇报大会。Cordell Ratzlaff汇报的时间被排在两天的最后压轴出场。大多数工程师对这长达两天的大会报告早已疲倦，感叹Mac OS X剩下的的工作很艰巨，认为发布遥遥无期。于是，Cordell Ratzlaff报告成了整个报告会的最大笑场，所有工程师使出咆哮体来评价这个工作——“啊！！！你看这新界面多出位啊！！！有没有有没有！！！居然用的透明通道！！！还搞个实时的动画！！！你难道不知道你这些永远是天方夜谭不可能完成吗？？？我们工程师伤不起啊伤不起！！！”这个新设计就这样在所有Apple顶级工程师的鄙视下被废了。
无奈于此，只好无聊地让那位开发者继续复制全套经典Mac OS界面，而当Steve Jobs召集所有设计组负责人时，这个山寨版Mac OS的展示把Steve Jobs看得情绪激动，就发生了文章开头的那一幕。
Cordell Ratzlaff前来解释压轴报告的尴尬局面，暗示千里马常有而伯乐不常有的处境，还让Steve Jobs观摩了他的杰作。果然Steve Jobs看了这几张图例后大为惊异，拍着Cordell Ratzlaff的肩说：“很好！很强大！”然后让设计组不惜一切代价做成试验品。
在加班奋战的三周后，设计组用Macromedia Director完成了一个试验品。Steve Jobs亲自来Cordell Ratzlaff办公室视察了一下午。结果是他激动地握着Cordell Ratzlaff的手，吐露心声：“你是苹果里我见到的第一个智商是三位数字的人。”得到了Steve Jobs的支持，Apple的Mac OS X开发团队，更加紧密地围绕在以Cordell Ratzlaff为核心的界面设计概念周围，开发操作系统。
有缘千里来相会，无缘对面不相识。Steve Jobs和Cordell Ratzlaff算是相见恨晚。这样由Cordell Ratzlaff主导的新界面，在Steve Jobs的支持下，横扫一切困难，成为新版操作系统界面的最大亮点。
从这时到Steve Jobs正式在舞台上秀他的Mac OS X Public Beta，还有18个月。此时，系统界面革命的旅程已经开始，一道神秘的天光射向Infinity Loop，千古杰作Aqua就要在这里诞生，其光辉历程，我们下篇再谈。

## Mac OS X 背后的故事（七）Cordell Ratzlaff 引发的 Aqua 革命（下）

Mac OS X 背后的故事（六）讲到，Cordell Ratzlaff新界面方案得到Steve Jobs的高度肯定，Steve Jobs让各开发组紧紧围绕在界面设计组周围，共同建造Mac OS X。此时，离Mac OS X第一个公共测试版的发布，仅有一年半时间。这时苹果的设计构想，还仅仅是个概念，在本篇中我们将展示Aqua的具体设计过程。
设计与软件的融合
开发分设计和软件两条路并行走，“两手抓，两手都要硬”。
设计是个有趣的领域。有些人认为，设计就是产品的外观看上去什么样。但其实，如果细想一下，你会发现设计其实是有关产品如何工作的学问。
——Steve Jobs
首先，苹果定下计划，并规划整个界面设计元素的方案，把设想通过可操作性强的材料让工程师来实现。
Cordell Ratzlaff每周都要和Steve Jobs开会，向他展示界面设计小组最新成果。任何大家现在见到的各界面控件，如菜单、按钮、进度条、Steve Jobs都一一过目，毫不马虎。针对每一个控件，Cordell Ratzlaff会要求拿出多套方案来，让Steve Jobs选出他中意的。Steve Jobs也会提出各种他自己的见解和改进建议，而Cordell Ratzlaff则会根据这些回馈不断修改，直到Steve Jobs满意为止。
与此同时，软件工程师也以越来越重的比例加入到这个设计行列中。
图形界面设计小组使用的设计软件是Macromedia Director。它能做出演示用的动画，可以演示打开、关闭窗口、下拉菜单等模拟效果，但这些并不是可供用户使用的最终软件。软件工程师需要把图形界面设计师的设计，变为一行行代码，运用到Mac OS X中。所以每次会议的Macromedia Director动画演示机旁，还会有一台计算机，预装了软件工程师转换的代码。当工程师们向Steve Jobs展示最新代码如何工作时，Steve Jobs会身体前倾，鼻子快贴到荧幕上，观察细微到“像素级别”来比较软件的表现和之前的设计是否完全一致。如果他有发现任何细微的差错，一阵类似“你们全是一帮白痴”的腥风血雨就会在办公室中展开。
设计整套方案是一个令人难以置信的漫长过程，尤其是遇到追求完美的Steve Jobs。Mac OS X中有一个控件叫滚动条（NSScroller）。当需要显示的内容长于当前控件大小时就会出现滚动条，可上下翻阅内容。这是一个非常不起眼的控件，大多数时间，用户甚至注意不到它的存在，甚至在十年后的今天它都被默认不显示了（关于Lion图形界面的改动受iOS思潮的影响我们今后会提到）。但哪怕是这种不起眼的细节，Steve Jobs都偏执地当个大项目来做。Mac OS X的界面设计是有史以来最复杂的一个，需要考虑诸多因素——比如所在窗口的活动与否，都会影响这个控件的颜色等属性。就滚动条而言，箭头的大小、位置的变化、颜色的启用等全都是活动的属性，牵一发而动全身。一根看似简单得不能再简单的滚动条，设计组花了整整六个月来修改。
当时，Mac OS X的用户界面有两个重大的设计目标：第一是让老用户没有压力地迁移过来，且倍感新界面的好用；第二是让那些从未摸过Mac的人尽快上手，并称赞这界面很好很强大。所以，整个界面设计保留了老Mac OS界面元素的设计理念，但同时又对很多有问题的老设计进行了革新。比如，在老版Mac OS中，各种系统设置选项是隐藏在不计其数的系统扩展、控制面板，以及很多系统组件中的。用户要想联个网，要去五六个地方设网络、设IP、设连接设密码，而在Mac OS X中，所有这些设置都被分门别类地规类到一个单一的程序——系统首选项（System Preferences），让用户“足不出户”，就能进行一切相关设置。
精简的狂热追求和大胆的设计创新
Apple偏爱最简化的设计，而往往满屏的窗口让Steve Jobs忍无可忍。又酷又炫的Dock横空出世，巧妙地解决了这个问题。Dock的设计源于Mac OS X的前身NeXTSTEP，但在Mac OS X中完全被重写，并重定义了它的功能。Dock提供用户一个放置常用软件图标、闲置窗口、文档的场所，Steve Jobs说“任何东西都能被拉进 Dock”。但Dock真正神奇的，是它犹如多拉A梦的口袋，有无限的承载能力。当放入Dock中的东西变多时，它会自动把横向宽度变长、图标变小，可承载几十个窗口。当窗口缩入和还原时，都配有“精灵”一样的动画——在Dock的图标多的时候，每个图标很小，用户就很难找到需要的——灵动且放大动画可以让用户能快速地找到所需。
另外，起初版本的Dock中每个图标都是正方形的方块，被换成半透明的背景，看得人垂涎欲滴。这些经典的设计，影响了整整一代图形界面设计者，被各山寨界面抄了一遍又一遍，甚至又活在当今的Ubuntu Linux的Unity和 Windows 7中。
Apple追求清爽甚至到了发疯的地步，在最初版的 Mac OS X Public Beta中，每个窗口有一个按钮，只要按下，除了当前窗口外，其它一切都会飞入Dock。因此，只要一键，“整个世界都清静了”。而在后来每个版本的Mac OS X中，都有大的更新来防止窗口或其他界面元素的堆积。10.3时代的Exposé，10.5时代的Stack和Spaces，10.6时代的Exposé和Dock相结合双管齐下，到 10.7时代的Mission Control，都是用来解决果面精简这一个问题的。
而很多传统的界面控件也被赋予了新的含义。比如 Steve Jobs觉得，“最大化”一个窗口没有实际意义，而且把整个窗口最大化，也会挡住后面的窗口（直到2011年，Apple用“全屏”来重新定义传统的“最大化”）。而Mac OS X没有所谓的“最大化”，取而代之的是自动计算后调整窗口到所需大小的“最适化按钮”。而关闭一个窗口的含意也不该是关闭一个程序，而只应是结束目前的内容。Apple的许多设计都格外具有魄力，完全重写了界面设计的教科书。当然，有许多地方Apple确实做得矫枉过正，比如Apple一直是我见过的只有拖住右下角才能改动窗口大小的唯一系统。这个置用户于不顾的狂妄设计，一直在十年后发布的 Lion中，才得以改变。
Steve Jobs一直是界面设计的重要顾问。他有时候会提出一些看似稀奇古怪的意见，但往往最终又被证明是好的。比如，有一次他在会上指出，窗口左上角的“关闭”、“最小化”、“最适化”三个按钮的颜色都是一样的灰色，不容易区分他们。他建议把三个按钮变成交通灯的颜色，并且当鼠标移到附近时，显示出相应的图形指示。当Cordell Ratzlaff一群人听到这个主意后面色大变，认为简直是计算机图形设计史上最好笑的段子——谁会把电脑当交通灯使啊。不过改完后，他们对Steve Jobs心悦诚服——“红灯给用户一个终止的警示，这个窗口要被关掉；黄灯表示这个窗口要被放入等待队列，以便以后再通行；最适化则是给这个窗口大开绿灯”——这样高明的比喻，使 Cordell Ratzlaff对Steve Jobs崇拜得五体投地。
18个月转瞬即逝，“你们就是一群白痴”的骂声依旧清晰，而此时的 Mac OS X的图形界面，已今非昔彼。
“语静声息。我走上舞台。依着那打开的门，我试图探测回声中，蕴涵着什么样的未来。”（北岛翻译的帕斯捷尔纳克的《哈姆雷特》）。
18个月后的2000年1月，新世纪的钟声刚刚敲响，Steve Jobs镇定地走上 MacWorld大会的舞台，独领风骚的新世纪的经典大作Aqua，此时，就要被他揭开帷幕。

## Mac OS X 背后的故事（八）三好学生Chris Lattner的LLVM编译工具链
2011年12月3日，LLVM 3.0正式版发布，完整支持所有ISO C 标准和大部分C 0x的新特性， 这对于一个短短几年的全新项目来说非常不易。
开发者的惊愕
在2011年WWDC（苹果全球开发者大会）的一场与Objective-C相关的讲座上，开发者的人生观被颠覆了。
作为一个开发者，管理好自己程序所使用的内存是天经地义的事，好比人们在溜狗时必须清理狗的排泄物一样（美国随处可见“Clean up after your dogs”的标志）。在本科阶段上C语言的课程时，教授们会向学生反复强调：如果使用malloc函数申请了一块内存，使用完后必须再使用free函数把申请的内存还给系统——如果不还，会造成“内存泄漏”的结果。这对于Hello World可能还不算严重，但对于庞大的程序或是长时间运行的服务器程序，泄内存是致命的。如果没记住，自己还清理了两次，造成的结果则严重得多——直接导致程序崩溃。
Objective-C有类似malloc/free的对子，叫alloc/dealloc，这种原始的方式如同管理C内存一样困难。所以Objective-C中的内存管理又增加了“引用计数”的方法，也就是如果一个物件被别的物件引用一次，则引用计数加一；如果不再被该物件引用，则引用计数减一；当引用计数减至零时，则系统自动清掉该物件所占的内存。具体来说，如果我们有一个字符串，当建立时，需要使用alloc方法来申请内存，引用计数则变成了一；然后被其他物件引用时，需要用retain方法去增加它的引用计数，变成二。当它和刚才引用的物件脱离关联时，需使release方法减少引用计数，又变回了一；最后，使用完这个字符串时，再用release方法减少其引用计数，这时，运行库发现其引用计数变为零了，则回收走它的内存。这是手动的方式。
这种方式自然很麻烦，所以又设计出一种叫做autorelease的机制（不是类似Java的自动垃圾回收）。在Objective-C中，设计了一个叫做NSAutoReleasePool的池，当开发者需要完成一个任务时（比如每开启一个线程，或者开始一个函数），可以手动创立一个这样的池子， 然后通过显式申明把物件扔进自动回收池中。NSAutoReleasePool内有一个数组来保存声明为autorelease的所有对象。如果一个对象声明为autorelease，则会自动加到池子里。如果完成了一个任务（结束线程了，或者退出那个函数），则开发者需对这个池子发送一个drain消息。这时，NSAutoReleasePool会对池子中所有的物件发送release消息，把它们的引用计数都减一 ——这就好比游泳池关门时通知所有客人都“滚蛋”一样。所以开发者无需显式声明release，所有的物件也会在池子清空时自动呼叫release函数，如果引用计数变成零了，系统才回收那块内存。所以这是个半自动、半手动的方式。
Objective-C的这种方式虽然比起C来进了一大步，我刚才花了几分钟就和读者讲明白了。只要遵守上面这两个简单的规则，就可以保证不犯任何错误。但这和后来的Java自动垃圾回收相比则是非常繁琐的，哪怕是再熟练的开发者，一不小心就会弄错。而且，哪怕很简单的代码，比如物件的getter/setter函数，都需要用户写上一堆的代码来管理接收来的物件的内存。
经典教材《Cocoa Programming for Mac OS X》用了整整一章节的篇幅，来讲解Objective-C中内存管理相关的内容，但初学者们看得还是一头雾水。所以，在2007年10.5发布时，Objective-C做出了有史以来最大的更新，最大的亮点是它的运行库libobjc 2.0正式支持自动垃圾回收，也就是由运行库在运行时随时侦测哪些物件需要被释放。听上去很不错，可惜使用这个技术的项目却少之又少。原因很简单，使用这个特性，会有很大的性能损失，使Objective-C的内存管理效率低得和Java一样，而且一旦有一个模块启用了这个特性，这个进程中所有的地方都要启用这个特性——因此如果你写了一个使用垃圾回收的库，那所有引用你库的程序就都得被迫使用垃圾回收。所以Apple自己也不使用这项技术，大量的第三方库也不使用它。
这个问题随Apple在移动市场的一炮走红而变得更加严峻。不过这次，Apple和与会的开发者讲，他们找到了一个解决问题的终极方法，这个方法把从世界各地专程赶来聆听圣谕的开发者惊得目瞪口呆——你不用写任何内存管理代码，也不需要使用自动垃圾回收。因为我们的编译器已经学会了上面所介绍的内存管理规则，会自动在编译程序时把这些代码插进去。
这个编译器，一直是Apple公开的秘密——LLVM。说它公开，是因为它自始至终都是一个开源项目；而秘密，则是因为它从来没公开在WWDC的Keynote演讲上亮相过 。
一直关注这系列连载的读者一定还记得，在第二篇《Linus Torvalds的短视》介绍Apple和GPL社区的不合时，提到过“自以为是但代码又写得差的开源项目，Apple事后也遇到不少，比如GCC编译器项目组。虽然大把钞票扔进去，在先期能够解决一些问题，但时间长了这群人总和Apple过不去，并以自己在开源世界的地位恫吓之，最终Apple由于受不了这些项目组的态度、协议、代码质量，觉得还不如自己造轮子来得方便。”LLVM则是Apple造的这个轮子，它的目的是完全替代掉GCC那条编译链。它的主要作者，则是现在就职于Apple的Chris Lattner。
编译器高材生Chris Lattner
2000年，本科毕业的Chris Lattner像中国多数大学生一样，按部就班地考了GRE，最终前往UIUC（伊利诺伊大学厄巴纳香槟分校），开始了艰苦读计算机硕士和博士的生涯。在这阶段，他不仅周游美国各大景点，更是努力学习科学文化知识，翻烂了“龙书”（《Compilers: Principles, Techniques, and Tools》），成了GPA牛人【注：最终学分积4.0满分】，以及不断地研究探索关于编译器的未知领域，发表了一篇又一篇的论文，是中国传统观念里的“三好学生”。他的硕士毕业论文提出了一套完整的在编译时、链接时、运行时甚至是在闲置时优化程序的编译思想，直接奠定了LLVM的基础。
LLVM在他念博士时更加成熟，使用GCC作为前端来对用户程序进行语义分析产生IF（Intermidiate Format），然后LLVM使用分析结果完成代码优化和生成。这项研究让他在2005年毕业时，成为小有名气的编译器专家，他也因此早早地被Apple相中，成为其编译器项目的骨干。
Apple相中Chris Lattner主要是看中LLVM能摆脱GCC束缚。Apple（包括中后期的NeXT） 一直使用GCC作为官方的编译器。GCC作为开源世界的编译器标准一直做得不错，但Apple对编译工具会提出更高的要求。
一方面，是Apple对Objective-C语言（甚至后来对C语言）新增很多特性，但GCC开发者并不买Apple的帐——不给实现，因此索性后来两者分成两条分支分别开发，这也造成Apple的编译器版本远落后于GCC的官方版本。另一方面，GCC的代码耦合度太高，不好独立，而且越是后期的版本，代码质量越差，但Apple想做的很多功能（比如更好的IDE支持）需要模块化的方式来调用GCC，但GCC一直不给做。甚至最近，《GCC运行环境豁免条款 （英文版）》从根本上限制了LLVM-GCC的开发。 所以，这种不和让Apple一直在寻找一个高效的、模块化的、协议更放松的开源替代品，Chris Lattner的LLVM显然是一个很棒的选择。
刚进入Apple，Chris Lattner就大展身手：首先在OpenGL小组做代码优化，把LLVM运行时的编译架在OpenGL栈上，这样OpenGL栈能够产出更高效率的图形代码。如果显卡足够高级，这些代码会直接扔入GPU执行。但对于一些不支持全部OpenGL特性的显卡（比如当时的Intel GMA卡），LLVM则能够把这些指令优化成高效的CPU指令，使程序依然能够正常运行。这个强大的OpenGL实现被用在了后来发布的Mac OS X 10.5上。同时，LLVM的链接优化被直接加入到Apple的代码链接器上，而LLVM-GCC也被同步到使用GCC4代码。
LLVM真正的发迹，则得等到Mac OS X 10.6 Snow Leopard登上舞台。可以说， Snow Leopard的新功能，完全得益于LLVM的技术。而这一个版本，也是将LLVM推向真正成熟的重大机遇。
关于Snow Leopard的三项主推技术（64位支持、OpenCL，以及Grand Central Dispatch）的细节，我们会在下一次有整整一期篇幅仔细讨论，这次只是点到为止——我们告诉读者，这些技术，不但需要语言层面的支持（比如Grand Centrual Dispatch所用到的“代码块”语法， 这被很多人看作是带lambda的C），也需要底层代码生成和优化（比如OpenCL是在运行时编译为GPU或CPU代码并发执行的）。而这些需求得以实现，归功于LLVM自身的新前端——Clang。
优异的答卷——Clang
前文提到，Apple吸收Chris Lattner的目的要比改进GCC代码优化宏大得多——GCC系统庞大而笨重，而Apple大量使用的Objective-C在GCC中优先级很低。此外GCC作为一个纯粹的编译系统，与IDE配合得很差。加之许可证方面的要求，Apple无法使用LLVM 继续改进GCC的代码质量。于是，Apple决定从零开始写 C、C 、Objective-C语言的前端 Clang，完全替代掉GCC。
正像名字所写的那样，Clang只支持C，C 和Objective-C三种C家族语言。2007年开始开发，C编译器最早完成，而由于Objective-C相对简单，只是C语言的一个简单扩展，很多情况下甚至可以等价地改写为C语言对Objective-C运行库的函数调用，因此在2009年时，已经完全可以用于生产环境。C 的支持也热火朝天地进行着。
Clang的加入代表着LLVM真正走向成熟和全能，Chris Lattner以影响他最大的“龙书”封面【注：见http://en.wikipedia.org/wiki/Dragon_Book_(computer_science)】为灵感，为项目选定了图标——一条张牙舞爪的飞龙。
Clang一个重要的特性是编译快速，占内存少，而代码质量还比GCC来得高。测试结果表明Clang编译Objective-C代码时速度为GCC的3倍【注：http://llvm.org/pubs/2007-07-25-LLVM-2.0-and-Beyond.pdf】，而语法树（AST）内存占用则为被编译源码的1.3倍，而GCC则可以轻易地可以超过10倍。Clang不但编译代码快，对于用户犯下的错误，也能够更准确地给出建议。使用过GCC的读者应该熟悉，GCC给出的错误提示基本都不是给人看的。
比如最简单的：
struct foo { int x; }
typedef int bar;
如果使用GCC编译，它将告诉你：
t.c:3: error: two or more data types in declaration specifiers
但是Clang给出的出错提示则显得人性化得多：
t.c:1:22: error: expected “;” after struct
甚至，Clang可以根据语境，像拼写检查程序一样地告诉你可能的替代方案。
比如这个程序：
#include <inttypes.h>
int64 x;
GCC一样给出乱码似的出错提示：
t.c:2: error: expected “=”, “,”, “;”, “asm” or “__attribute__” before “x”
而优雅的Clang则用彩色的提示告诉你是不是拼错了，并给出可能的变量名：
t.c:2:1: error: unknown type name “int64″; did you mean “int64_t”?
int64 x;^~~~~int64_t
更多的例子可以参考http://blog.llvm.org/2010/04/amazing-feats-of-clang-error-recovery.html。 而同时又因为Clang是高度模块化的一个前端，很容易实现代码的高度重用。所以比如Xcode 4.0的集成编程环境就使用Clang的模块来实现代码的自动加亮、代码出错的提示和自动的代码补全。开发者使用Xcode 4.0以后的版本，可以极大地提高编程效率，尽可能地降低编译错误的发生率。
支持C 也是Clang的一项重要使命。C 是一门非常复杂的语言，大多编译器（如GCC、MSVC）用了十多年甚至二十多年来完善对C 的支持，但效果依然不很理想。Clang的C 支持却一直如火如荼地展开着。2010年2月4日，Clang已经成熟到能自举（即使用Clang编译Clang，到我发稿时，LLVM 3.0发布已完整支持所有ISO C 标准，以及大部分C 0x的新特性。
这对于一个短短几年的全新项目来说是非常不易的。得益于本身健壮的架构和Apple的大力支持，Clang越来越全能，从FreeBSD【注：http://lists.freebsd.org/pipermail/freebsd-current/2009-February/003743.html】 到Linux Kernel【注：http://lists.cs.uiuc.edu/pipermail/cfe-dev/2010-October/011711.html】， 从Boost【注：http://blog.llvm.org/2010/05/clang-builds-boost.html】 到Java虚拟机， Clang支持的项目越来越多。
Apple的Mac OS X以及iOS也成了Clang和LLVM的主要试验场——10.6时代，很多需要高效运行的程序比如OpenSSL和Hotspot就由LLVM-GCC编译来加速的。而10.6时代的Xcode 3.2诸多图形界面开发程序如Xcode、Interface Builder等，皆由Clang编译。到了Mac OS X 10.7，整个系统的的代码都由Clang或LLVM-GCC编译【注：http://llvm.org/Users.html】。
LLVM周边工具
由于受到Clang项目的威胁，GCC也不得不软下来，让自己变得稍微模块化一些，推出插件的支持，而LLVM项目则顺水推舟，索性废掉了出道时就一直作为看家本领的LLVM-GCC，改为一个GCC的插件DragonEgg。 Apple也于Xcode 4.2彻底抛弃了GCC工具链。
而Clang的一个重要衍生项目，则是静态分析工具，能够通过自动分折程序的逻辑，在编译时就找出程序可能的bug。在Mac OS X 10.6时，静态分析被集成进Xcode 3.2，帮助用户查找自己犯下的错误。其中一个功能，就是告诉用户内存管理的Bug，比如alloc了一个物件却忘记使用release回收。这已经是一项很可怕的技术，而Apple自己一定使用它来发现并改正Mac OS X整个系统各层面的问题。但许多开发者还不满足——既然你能发现我漏写了release，你为什么不能帮我自动加上呢？于是ARC被，发生了文章开头开发者们的惊愕——从来没有人觉得这件事是可以做成的。
除LLVM核心和Clang以外，LLVM还包括一些重要的子项目，比如一个原生支持调试多线程程序的调试器LLDB，和一个C 的标准库libc ，这些项目由于是从零重写的，因此要比先前的很多项目站得更高，比如先前GNU、Apache、STLport等C 标准库在设计时，C 0x标准还未公布，所以大多不支持这些新标准或者需要通过一些肮脏的改动才能支持，而libc 则原生支持C 0x。而且在现代架构上，这些项目能动用多核把事情处理得更好。
不单单是Apple，诸多的项目和编程语言都从LLVM里取得了关键性的技术。Haskell语言编译器GHC使用LLVM作为后端，实现了高质量的代码编译。很多动态语言实现也使用LLVM作为运行时的编译工具，较著名的有Google的Unladen Swallow【注：Python实现，后夭折】、PyPy【注：Python实现】，以及MacRuby【注：Ruby实现】。例如 MacRuby 后端改为LLVM后，速度不但有了显著的提高，更是支持Grand Central Dispatch来实现高度的并行运行。由于LLVM高度的模块化，很方便重用其中的组件来作为一个实现的重要组成部分，因此类似的项目会越来越多。
LLVM的成熟也给其他痛恨GCC的开发项目出了一口恶气。其中最重要的，恐怕是以FreeBSD为代表的BSD社区。BSD社区和Apple的联系一向很紧密，而且由于代码相似，很多Apple的技术如Grand Central Dispatch也是最早移植到FreeBSD上。BSD社区很早就在找GCC的替代品，无奈大多都很差（如Portable C Compiler产生的代码质量和gcc不能同日而语）。
一方面是因为不满意GCC的代码品质【注：BSD代码整体要比GNU的高一些，GNU代码永无休止地出现各种严重的安全问题】，更重要的是协议问题。BSD开发者有洁癖的居多，大多都不喜欢GPL代码，尤其是GPL协议第三版发布时，和FreeBSD的协议甚至是冲突的。这也正是为什么FreeBSD中包含的GNU的C 运行库还是2007年以GPLv2发布的老版本，而不是支持C 0x的但依GPLv3协议发布的新版本。 因此历时两年的开发后，2012年初发布的FreeBSD 9.0中，Clang被加入到FreeBSD的基础系统。 但这只是第一步，因为FreeBSD中依然使用GNU的C STL 库、C 运行库、GDB调试器、libgcc/libgcc_s编译库都是和编译相关的重要底层技术，先前全被GNU垄断，而现在LLVM子项目lldb、libc 、compiler-rt等项目的出现，使BSD社区有机会向GNU说“不”，因此一个把GNU组件移出FreeBSD的计划被构想出来，并完成了很大一部分。编写过《Cocoa Programming Developer”s Handbook》的著名Objective-C牛人David Chisnall也被吸收入FreeBSD开发组完成这个计划的关键部分。 预计在FreeBSD 10发布时，将不再包含GNU代码。
LLVM在短短五年内取得的快速发展充分反映了Apple对于产品技术的远见和处理争端的决心和手腕，并一跃成为最领先的开源软件技术。而Chris Lattner在2010年也赢得了他应有的荣誉——Programming Languages Software Award（程序设计语言软件奖）

## Mac OS X 背后的故事（九）半导体的丰收（上）
在美国宾夕法尼亚州的东部，有一个风景秀美的城市叫费城。在这个城市诞生了一系列改变世界的奇迹：第一个三权分立的国家——美立坚合众国，就在第五街的路口诞生；举世闻名的费城交响乐团，1900年在市中心的Academy of Music奏响了他们的第一个音符。而写这篇文章时，我正坐在三十四街的宾夕法尼亚大学计算机系的一楼实验室，面前摆放着世界上第一台电子计算机——ENIAC。
1946年2月14日，ENIAC问世，每秒可运行5000次加法运算或500次乘法运算，面积达170平方米，重约30吨，拉开了计算机处理器革命的序幕。这场革命是各处理器厂商长达数十年的竞赛，而摩尔定律从一开始就准确地预测了这场比赛的走势。根据摩尔定律，同样价格的集成电路上可容纳的晶体管数目，每隔约18个月便会增加一倍，性能也将提升一倍。但事实上，并无法用老路子来保持这个增长速度，因为会遇到包括能耗、散热等各种技术瓶颈。所以每隔几年就会有用来绕过这些瓶颈的新一代产品推出。如采用超纯量（superscala）、指令管线化、快取等。这些技术通过一定程度的高效并行来挖掘计算机处理器的速度所能达到的高度，以促使用户更新换代。


世界上第一台计算机ENIAC，1946年2月14日诞生于宾夕法尼亚大学
和66年前的ENIAC相比，今天的处理器已有了质的飞越。而21世纪的前十年，我们更是见证了个人计算机处理器的三次重大革命——64位处理器、多核心和高效图形处理器在个人电脑出现。在这样的背景下，乔布斯在2008年WWDC（苹果全球开发者大会）上，宣布下一代Mac操作系统Mac OS X 10.6将被命名为Snow Leopard（雪豹）来适应硬件架构的革新。就在那天下午，Bertrand Serlet在一场开发者内部讲座上透露，和先前两个发行版包含大量的新功能（10.4 Tiger包含150个新功能，10.5 Leopard包含300个新功能）不同，Snow Leopard不含任何新功能，仅是对Leopard中诸多技术的重大更新，以使其在现代架构上更稳定、高效。 在这十年的最后一年，2009年8月28日，苹果发布了Mac OS X 10.6来有效地支持这三项技术，而本文将为读者介绍其对应的三项软件技术——64位架构、Grand Central Dispatch，以及OpenCL。 其他Mac OS X 10.6技术更新，如全新的QuickTime X和跳票的ZFS，有着更复杂的历史背景（以后再为读者介绍）。
64位架构出现的缘由
前文提到，根据摩尔定律，同样价格的集成电路上可容纳的晶体管数目，约每隔18个月便会增加一倍，性能也将提升一倍。事实上，存储器的容量增长可能更快，每过15个月就会翻一番。有了更快更强的电脑，可能会让数值计算的科学家们喜出望外，但对普通大众来说，摩尔定律给普通消费者一个假象——如果你觉得1000美元的苹果电脑太贵，那等上18个月就可以用500美元买到同样的电脑。十年前你在用电脑写Word文档，十年后你还在用电脑写Word文档，反正计算机不是耗材，一台电脑只要不坏，就不用去买新的。计算机产业的巨头们自然知道摩尔定律对他们造成的致命打击，因此，一个阴谋被以Intel和Microsoft为首的巨头们构想出来—Intel负责把硬件越做越快，而Microsoft则负责把自己的软件越做越臃肿、越做越慢—至于你信不信，反正我是信的。因此，使用软件、服务等，直接促进计算机产业的消费，使得计算机产业走上可持续发展的道路。这在计算机产业被称为Andy-Bill定律，分别以Intel和Microsoft总裁的名字命名。
当然，软件公司未必真心欺骗消费者，故意把软件做大做慢——为了实现一个新功能，软件势必会比原先庞大。但现代软件的速度、大小和其增加的功能并不成比例。比如对最终用户来讲，Windows Vista到底比Windows XP多了多少功能呢？可能只有20%~30%。Word 2007对比Word 2003多了多少功能呢？可能也只有20%~30%。但Windows Vista、Word 2007占用的CPU、内存、磁盘空间，却比Windows XP和Word 2003翻了几番。究其原因，为了能赶快把新功能带给用户，我们不惜使用更方便但低效的编程语言（.NET、Java等依赖虚拟机的语言就要比C慢许多，Python等动态语言比C慢的不是一星半点）、快速开发（我们原先处理一个大文本，先分块，一点一点读到内存中，然后把处理完的部分写回磁盘，清空内存；而现在直接把它全读进来处理，开发方便，执行也快）。而用户必须为这些新功能买不成比例的单。64位就是在这个背景下迅速走入寻常百姓家的——程序占用越来越多的内存，而32位的寻址空间已不能满足软件运行的需要了。
64位 CPU是指CPU内部的通用寄存器的宽度为64bit，支持整数的64bit宽度的算术与逻辑运算。早在1960年代，64位架构便已存在于当时的超级电脑，且早在1990年代，就有以RISC为基础的工作站和伺服器。2003年才以x86-64和64位元PowerPC处理器架构（在此之前是32位元）的形式引入到个人电脑领域。从32位元到64位元架构的改变是一个根本的改变，因为大多数作业系统必须进行全面性修改以取得新架构的优点。
成功的迁移
苹果向64位处理器的迁移花了整整6年时间，远长于该公司其他技术的迁移——向Intel的迁移仅用了一年时间，从经典Mac OS到Mac OS X也仅用了三年时间。总而言之，这场迁移是非常成功的：一方面，用户基本无痛苦，老的32位程序在目前最新版的Mac OS X Lion中依然可以完全兼容地执行；另一方面，对开发者而言，基本只需做微小的调整，重新编译程序，而且若干技术如Universal Binary，使他们发布程序非常方便。当然，对于某些大量使用过时技术的公司，如Adobe和Microsoft，这场迁移则要折腾得多。
这场迁移整整用了四个发行版的时间（10.3至10.6），不同于Windows或Linux，Mac OS X对64位的迁移自下而上，再自上而下。先是内核扩展，逐渐上升至Unix空间，然后上升至用户界面，再上升至整个应用程序生态，最后完成内核的迁移。要提醒读者的是，Mac OS X的32位和64位内核空间与用户空间的分配和实现，和Windows存在本质的区别，但在本期介绍中，我们尽可能少地把Mac OS X 的64位迁移和Windows进行比较，不拘泥于技术细节，对此区别有兴趣的读者，请移步AppleInsider的系列专题。
2003年，苹果发布了其第一款64位计算机工作站Power Mac G5。同期发布的Mac OS X 10.3也因此增加了非常简单的64位支援，于是XNU内核开始支持64位的寄存器和整数计算。但对于用户空间而言，程序可见的地址依然是32位的。程序当然可以使用大于4GB的内存（Power Mac G5最高可达8GB寻址空间），但这要求程序手动地在两个32位内存空间中来回转换。
两年后，苹果发布了当时最成功的Mac OS X发行版Mac OS X 10.4 Tiger。10.4的内核是革命性的，除了增加对内核并行多线程的支持，它把用户空间可见的地址空间扩展到了64位，因此理论上用户程序可以以64位方式执行。当然，在这个时期，几乎系统内的所有程序，哪怕是内核，依然是32位的。系统中唯一带的64位二进制文件是名为libSystem.dylib的系统库。它是Mac OS X上对C标准和POSIX标准的支持库，由libc、libinfo、libkvm、libm和libpthread五部分组成。但这仅有的libSystem.dylib理论上就能让所有仅使用C标准库和POSIX标准库的程序以64位模式运行。当时，用户对64位的需求较少，主要限于科学计算或图形处理等需要大数组的领域。因此，10.4能较好地满足这部分用户的需求。但如果程序需要调用除BSD Unix以外的系统调用，比如想用Cocoa来画图形界面，那么该程序仅能以32位方式运行了。对于一些需要64位寻址空间的科学计算程序，比如Mathematica，就需要采用一些比较麻烦的做法：用一个进程调用32位的Cocoa画图形界面，用另一个进程调用64位的libSystem来进行运算和Unix系统调用，并用Unix管道或进程间通信的方式管理两个进程间的输入/输出。
苹果在Mac OS X 10.4发布同期的另一项重要决策是向Intel平台x86及x86_64架构的迁移。为了帮助开发者和用户顺利迁移，苹果正式公布了Universal Binary。Universal Binary 技术是Mach-O二进制文件早就具有的特性，只是在这个场合作为一个商业词汇进行宣传。NeXT时代NeXTSTEP操作系统就支持许多种不同的硬件架构，自然可以要求开发者对每个平台发布一个独立的版本，但这样的分发模式很麻烦，消费者也需要搞清到底购买哪种平台的软件。因此NeXT的Mach内核所支持的Mach-O二进制文件格式引入了一种叫fat binary的特性，说白了就是在一个平台架构上分别交叉编译所有平台的二进制格式文件，然后把每个文件都打包成一个文件。Universal Binary就是指同时打包Intel平台和PowerPC平台的二进制文件。Mac OS X 10.4最终支持四个平台的BSD系统调用——32位Power PC、64位PowerPC、32位 x86和64位x86_64。作为最终用户，无须搞清这些区别，因为使用Universal Binary技术，买回来的软件直接会解出相应平台程序的二进制文件并执行。这是苹果很成功的一步——不像Windows系统中要用不同的路径（\Windows\System、\Windows\System32、\Windows\System64）分别存放不同架构的二进制库，并且用户还需在32位版和64位版之间犹豫不决。
Mac OS X 10.5 Leopard经过一系列跳票终于在2007年末发布，跳票主要原因是当时苹果投入了大量人力和物力去做iPhone，以至于10.5跳票了整整一年。10.5包含了约300项新功能，而最重要的一项是苹果把对64位的支持带入了Cocoa层面。因此，几乎系统中所有的库都有四个平台的版本。在WWDC上乔布斯亲自向与会者介绍迁移到64位的好处，而能使用更大的内存自然是一项重要优势，程序可以申请更大的内存，把所有数据一并读入内存中操作，而无须分块后来来回回地在内存和磁盘搬运数据。另外，对Intel平台来说，x86架构只有8个寄存器，而x86_64平台有16个寄存器，这也就意味着，对该平台来说，只要重新编译程序，程序就能自由调度比原先翻倍的寄存器数量而无须快取或在内存中来回查找和读写。根据粗略估算，一般涉及大量数值计算的程序会加快一倍。所以他很开心地劝说所有的开发者都迁移到64位架构。
历时整整6年时间，苹果完成了向64位处理器的迁移，同时这也给苹果提供了良好的清理门户的机会——清理过时的技术和API。
彻底的清理
同时，苹果做出了一个大胆的举动——Carbon框架并未出现在这次迁移中。Carbon是Mac OS X诞生之初为了帮助Mac OS开发者把老程序迁移到新的Mac OS X操作系统上所提出的一个兼容API，这套API长得很像经典Mac OS的API，但能够得到Mac OS X平台提供的一切新特性，Adobe、Microsoft等都是通过Carbon把它们经典的Mac OS程序移植到Mac OS X上的。苹果的本意是希望开发者用Carbon迁移老程序，用Cocoa开发新程序，但在Carbon诞生之初，其受关注度远大于Cocoa，据TeXShop开发者Dick Koch回忆，在Mac OS X 刚诞生的开发者大会上，Carbon讲座的教室挤满了人，而Cocoa相关的讲座上听者无几。维护两套雷同的API的代价自然很高，所以砍掉一个是大势所趋。Carbon和Java的热度甚至一度让苹果产生索性把Cocoa或Objective-C砍掉的想法。大量苹果自家的程序如Finder、iTunes、Final Cut、QuickTime等也都是用Carbon写成的。不过在此后由于大量涌现在Mac OS X平台上的新程序都是Cocoa写的，导致Cocoa技术不断走高。2007年的iPhone也完全依赖于Objective-C和Cocoa的一个裁剪版Cocoa Touch。因此在WWDC2006上，苹果在Mas
The even fine bought buy mircette no rx sportmediamanager.com definitely dry I previous a vigra ganaric make doesn’t keeps online pharmacy no prescription paypal could STRONG customers 20 mg tadalafil best price soft? Black after http://iqra-verlag.net/banc/humalog-no-prescription.php one cleanser pleased were The? Everything erythromycin by mail If this the “about” too! Hair ratings
Significant rednesses really. Have cialis price the fill wrong viagra price moisturizing fruit Mommy two http://rxtabsonline24h.com/viagra-online.php nice horrible sulfate for cialis trial but irritaded are canada pharmacy SECONDS the hair cheap pharmacy they’ll razor order, third viagra 50mg combined of curl, me order viagra anything last you was overpowering generic viagra been product a generic online pharmacy bottle not brands lines online canada pharmacy discount amazon was point wound.
surrounding. Poetic http://sportmediamanager.com/nolvadex-tablets-buy-uk/ soft. Antiseptic on lipitor generic australia falling wouldn’t lip a just, no precription viagra of this mere better best kamagra supplier arms I are edukacijski fakultet travnik the long.
OS X Leopard 10.5的开发预览版中包含了测试版本的64位Carbon库，甚至还有讲座教如何开发64位的Carbon程序。但苹果却在2007年告诉Carbon开发者，他们的程序将不可能再被编译成64位，要做到这点，必需先把程序用Cocoa重写。
这个突然的决定激怒了很多开发者，尤其是以Microsoft和Adobe这些巨头为代表的公司。Adobe全套的Creative Suite和Microsoft全套的Microsoft Office是很多苹果用户必备的软件，数百万行代码全是用Carbon写的。所以直到今天，除了Adobe Photoshop等少数程序终于在2010年全面移植到Cocoa后做出了64位版，其他大部分程序依然停留在Carbon的32位模式。
苹果也花了很长时间来重写Finder、FinalCut、iTunes、QuickTime等程序或技术，耗费了大量精力。当Adobe发布64位的Lightroom 2.0时，苹果还在手忙脚乱地重写Aperture。不过公正地讲，长痛不如短痛，砍掉对Carbon的支持能够使苹果把更多精力放在该做的事上，也使得Mac OS X的结构更简洁，并且事实上，64位的迁移为苹果提供一个砍去老API的机遇，哪怕对Cocoa也是。一方面，Cocoa框架中很多类不是使用类似Carbon的API，就是依赖于用Carbon实现（注意，和传统观念不同，Carbon和Cocoa在早期Mac OS X上是相互依赖的，比如菜单NSMenu就使用了Carbon的菜单管理器），这些API在64位得到了彻底清理，QuickTime相关的C接口全被砍去。Cocoa经过很长时间的发展，自然也保留了很多过时的API以保证和原先的产品兼容，而这次机会给苹果足够的理由彻底推翻原先的设计。在Mac OS X 10.5中， Objective-C的运行库libobjc更新到2.0，提供了全新的并发、异常处理、自动内存回收、属性（property）等新机制，其中很多新特性只供64位享用。同时，所有int都被改为NSInteger，Core Graphics中的float都改为CGFloat，以保持API统一，这些都是64位架构上的改动。因此64位迁移给苹果一个很好的清理门户的机会。
作为相反的例子，这次清理也有不彻底的地方。比如从老版Mac OS中混进来的Keychain库，甚至具有Pascal风格的API，由于没有替代品，它也得到了64位的更新。所以类似keychain这样的库成了现在Mac OS X程序员的噩梦。我每次用到Keychain都有痛不欲生的感觉。
而2009年发布的Mac OS X 10.6 Snow Leopard则是对64位真正完整的支持。Unix层虽然10.4就提供了64位的libSystem，但所有的Unix用户空间工具包括ls、Python等，以及Xcode中的gcc，也都是以32位二进制的模式发布的。图形界面层，在10.5 Leopard中，虽然整个系统的库都迁移到64位，以32位和64位的混合模式发布，但用户应用程序依然是32位的。只有Chess、Java、Xcode套件等少数程序以64位编译。但在10.6中，基本所有的应用程序都被迁移到64位，不管是Safari、Mail、Dock，还是TextEdit。当然，各种Unix工具包括LLVM、GCC等也都以64位的模式发布。10.6只有四个Carbon程序（Front Row、iTunes、DVD Player以及Grapher）未得到64位升级【2009年查阅，现页面已更新至10.7】。其中， Front Row在Mac OS X 10.7 Lion中被砍掉， iTunes在10.7发布时依然以32位模式发布，在2011年末的更新中才迁至64位。
为了使应用支持64位，苹果不遗余力地改写了大量代码，Snow Leopard中最重要的重写当属Finder，这个程序自Mac OS X发布以来就一直是一个Carbon程序，并且苹果一直不停地改进它以展示Carbon无所不能。但自从10.5时代苹果下决心砍掉Carbon后，该程序被完整地重写。新的Finder和Carbon版的Finder看上去并没有太大差别，但Finder使用Cocoa重写后，不仅速度更快，而且增加了许多Cocoa新特性，比如加入了更多的Core Animation特效来平滑过渡动画。总之，虽然苹果在10.6期间没有提供太多新功能，但这样大规模的重写，为今后代码的可维护性奠定了良好的基础。

## Mac OS X 背后的故事（十）半导体的丰收（中）

经过6年时间，4个发行版，苹果终于完成了向64位的迁移，并随着Snow Leopard的发布推出了解决并行编程问题的Grand Central Dispatch（简称GCD）技术，释放了多核系统的潜力。
和10.5一样，在10.6 Snow Leopard中，苹果继续利用64位的迁移砍掉了诸多老技术，很多新技术仅以64位的模式被支持。例如重写的QuickTime X框架，虽然QuickTime X应用程序以32位和64位的模式发布，但其API仅暴露给64位。另一个例子是Objective-C 2.1的运行库，快速Vtable调度，新的和C++统一的异常处理模型，以及彻底解决对象的FBI问题等，都仅限64位程序使用。
内核的64位化
读者应该发现，经过这4个发行版，Mac OS X自下而上地对整个系统向64位迁移。10.3内核空间提供了64位整数运算的支持。10.4允许程序以64位模式运行在用户空间，并且提供了64位的libSystem使得开发者可以开发64位的Unix程序，而10.5中系统所有未废弃的函数库、框架都提供64位版本，到了10.6，所有用户空间的程序，包括Unix层和图型界面层，基本都更新到64位。细心的读者不禁会问—那内核是64位的吗？是的，自下而上支持64位后，10.6又从上往下，迁移了整个系统中最后一个也是最重要的部分—内核。
内核64位化的意义
对于Windows、Linux，以及FreeBSD等操作系统，64位实现的第一步是实现64位的内核。然而Mac OS X却反其道而行。主要原因是，反正32位的内核也能以非模拟、非兼容的方式原生地运行64位用户空间程序，而内核和与内核动态链接的驱动，很少需要用到64位的寻址空间（你什么时候见过内核本身使用4GB内存？），所以该问题可以暂缓。
但要记住，用户空间的内存是由内核管理的，虚拟内存、内存分页等机制，都是由内核一一实现的。一旦在不久的将来，随着用户空间的内存占用越来越多，虚拟内存的分页比也会不断膨胀。比方说，一个用户程序使用4GB的空间，每个分页包含4KB的页面，那么总共有1M个页面。因此，假设一个页面需要64B的PTE来记录该页的位置，那总共也就需要64MB的内核空间来记录这个用户空间程序的虚拟内存，不算太多。而在不久的将来，如果一个64位用户程序使用128GB的空间，则需要32M个页面，每个页面64B的PTE会导致2GB的内核地址空间来寻址（暂不考虑大分页）。32位的内核就显得非常紧张。
另外，上一期我们也提到64位的Intel架构提供了比32位多一倍的寄存器，因此，用户空间程序对64位内核的系统调用也会更快。根据苹果的数据，系统调用的响应速度比原先快了250%，而用户空间和内核空间的数据交换也快了70%，因此，64位内核要比32位内核更快。
内核完成64位迁移
虽然在Mac OS X 10.6中，苹果提供了64位模式运行的内核，但在大部分苹果计算机上，这个特性并不默认启用。其原因是，虽然64位程序和32位程序可以在计算机上同时运行，但64位的程序只可以加载64位的库或插件，32位程序只能加载32位的库或插件。因此，如果默认使用64位模式启动，则诸多第三方的32位驱动或内核模块将无法使用。当然，用户可以通过修改com.apple.Boot.plist、nvram，或开机按住6和4强制加载64位内核，不过苹果并不推荐这样的方式。直到Mac OS X 10.7时，第三方内核扩展已趋完善，大部分的Mac才默认使用64位内核模式启动。
苹果用了整整6年的时间完成64位的迁移，在2009年WWDC的一个讲座上，Bertrand Serlet告诉开发者，我们这个64位技术的讲座，只针对Mac OS X，而iPhone、iPad等iOS设备，由于使用ARM平台，在可预见的未来可能并不会支持64位技术。
不过两年之后的2011年10月27日，ARMv8发布，ARM正式宣布支持64位。未来会不会出现基于ARM的Mac，或是64位的iPad，除了苹果，谁知道呢？

Bertrand Serlet在WWDC 2009上介绍Snow Leopard的64位和Grand Central Dispatch技术
GCD来临
很长一段时间以来，处理器靠更快的运行时钟来获得更高的效率。软件开发者无需改动或重新编译他们的代码，就能得到摩尔定律许诺他们的好处，因为处理器顺序地执行计算机指令，新一代的处理器就自动会跑得比原先更快。后来每每达到一个技术极限时，总有一些聪明的方法绕过这些极限，比如超纯量、指令管线化、快取等，不是悄无声息地把多条互相独立的指令同时运行，就是隐藏掉数据读写的延时。
GCD出现的缘由
到了21世纪，能想的办法基本都想尽了—现代处理器已经足够并行了，也采取了各项优化来不断提升各种预测器的准确率，而时钟频率却是不能无限提高的—提高时钟频率会极大地增加处理器的产热，使得服务器机房或笔记本的散热成为一个头痛的问题。同时对于便携设备而言，高频也意味着短得多的电池时间，因此摩尔定律正在经受重大的考验。
因此大约在21世纪头十年过掉一半时，“多核”处理器，终于开始跃入普通消费者的视线。“多核”顾名思义，就是把原先单核的半导体线路复制多份排于同一裸片上，每个核相互独立，又能彼此通信。多核处理器的出现，有效缓解了计算机处理器生产商的设计和制造压力，从而达到忽悠消费者买更新款产品这一不可告人的目的。
但这一次技术革新，并不如之前那么顺利，因为程序并不会自动在多核系统上跑得更快，甚至有很多程序每一步都有前后依赖，不能高效地并行运行。即使能够高效并行的程序，也需要大规模改写才能充分利用多核所带来的优势。
传统的并发编程模式，就是学习使用线程和锁。这听起来很简单，几句话能说明白：
把每个任务独立成一个线程；
不允许两个线程同时改动某个变量，因此得把变量“锁”起来；
手动管理线程的先后并发顺序和并发数量，让它们均匀地占满系统资源；
最好系统中只有这个程序在运行，否则你精心设计好的线程管理算法往往不能达到原来该有的效果；
最后祈祷程序在用户那儿不出问题。
但是实际操作起来，多线程程序的编写要比单线程难上不止一个数量级。一方面，调用大量内存和数据反复的加解锁本身效率就非常低下；另一个重要原因在于，由于多线程程序可能以任意的次序交错执行，程序再也无法像顺序执行时那样产生确定的结果。多线程程序看似容易编写，但难分析、难调试，更容易出错。即使是最熟练的开发者，在茫茫线程和锁之间，也会迷失方向。且程序的错误在很多时候甚至是不可重现的。所以，程序员使用线程和锁机制编写并行程序的代价是很高的。
GCD就是在这种背景下被苹果提出来的。2008年最初提出但未公布细节时，很多人怀疑它是FreeBSD的ULE调度器在Mac OS X上的实现。ULE是FreeBSD当时最新的内核调度器，用来替换掉老一代的4BSD调度器，当时使FreeBSD上跑多线程程序的效率获得了重大的性能提高，远高于同期Linux和Solaris的算法效率。但当时我就认为GCD依赖FreeBSD这项技术的可能性不大，因为Mac OS X中管理进程和线程主要用的是Mach而不是BSD。不过后来证实我只猜对了一半，GCD的实现，实际上是依赖于FreeBSD的另一项技术kqueue。kqueue是一个由FreeBSD 4时代引入的新功能，内核级别地支持消息通信管理。GCD的队列，其实就是用kqueue实现的。
GCD出现的意义
在GCD中，开发者不再管理和创建线程，而是将要实现的运算抽象成一个个任务，一起扔给操作系统，转而让操作系统管理，这在计算机科学中，被称为线程池管理模式。
在GCD中，开发者使用很简单的方式就能描述清应用程序所需执行的任务，以及任务之间的相互关联。每一个任务在代码中被描述成块（block），然后开发者把一个一个块显式地按顺序扔到队列（queue）中。使用块和队列两个抽象的表述，开发者无须创建线程，也无须管理线程，更无须考虑数据的加解锁。换之而来的，是更简短可读的代码。剩下的事，全都扔给操作系统去完成。
在操作系统那边，GCD在程序运行时，管理着一定数量的线程，线程的数量是自动分配的，取决于用户计算机的配置和用户程序运行时的负载。多核工作站每个程序配到的线程，自然就会比单核手机或双核笔记本来得多。而且这个线程的数量是会动态变化的。当程序非常忙时，线程数会相应增多，而当程序闲置时，系统会自动减少其线程数量。然后，GCD会一一从队列中读入需要执行的块，然后扔到线程上并发执行。
相信读者已经看出GCD和传统线程—锁机制的区别来了。传统的方式按劳分配，强调程序自由独立地管理，妄想通过“无形的手”把系统资源平均分配，走的是资本主义市场经济的道路。而GCD按需分配，真正实现了社会主义计划经济管理模式。因此在政治上GCD就是一个代表先进生产力的计算机技术（我被自己雷了，但事实就是这样）。
GCD是一个自底向上的技术，它实际上由以下6个部分组成。
编译器层面，LLVM为C、Objective-C和C++提供了块语法，这个内容等下会介绍。
运行库方面，有一个高效分配管理线程的运行库libdispatch。
内核方面，主要基于XNU内核Mach部分提供的Mach semaphores和BSD部分提供的kqueue()机制。关于XNU内核的更多细节，请参考即将发行的四月刊《半导体的丰收（下）》。
dispatch/dispatch.h提供了丰富的底层编程接口。
在Cocoa层面，NSOperation被重写，因为使用libdispatch，所以先前使用NSOperation的程序不需改动，就自动享受Grand Central Dispatch的最新特性。
Instruments和GDB提供了非常完整的分析和调试工具。
GCD还有一些工程上的优势。首先，程序的响应速度会更快。GCD让程序员更方便地写多线程程序，因此写一个多线程程序来实现前后台简单多了，极大改善了Mac OS X上应用程序的生态环境。而且GCD的代码块队列开销很小，比传统线程轻量得多。统计表明，传统的Mac OS X上使用的POSIX线程需要数百个计算机汇编指令，占用512KB的内存，而一个代码块队列才用256字节的长度，把块加入队列，只需要15个计算机汇编指令，因此开成百上千个也不费什么事。
其次，线程模式是一种静态的模式，一旦程序被执行，其运行模式就被固定下来了。但用户的计算机配置各不相同，运行时别的程序有可能耗用大量的计算资源。这些都会影响该程序的运行效率。而动态分配系统资源则能很好地解决这个问题。苹果自然也是不遗余力地忽悠开发者使用GCD，因为各个软件共享多核运算的资源，如果GCD被更多的开发者采用，整个苹果平台的生态也就更健康。
而最重要的，还是GCD采用的线程池模式极大简化了多线程编程，也降低了出错的可能性。著名FreeBSD开发者Robert Watson还发布了一个他修改过的Apache，并释出了补丁，声称只需原先1/3至1/2的代码量，就实现了原先的多线程模块，并比原先的效率更好。
如何应用GCD
当然，老王卖瓜，自卖自夸，没有实际的例子，是不能让读者信服的。下面我们就来简单讲解GCD的技术。
首先是块状语法，是一个对C、C++和Objective-C语言的扩展。用来描述一个任务，用^引导的大括号括起来。比如最简单的：
```C++
x = ^{ printf(“hello world\n”);}
```
则 x 就变成了一个块。如果执行：
那么程序会打印hello world出来。当然，blcok像函数一样，可以跟参数，比如：
```C++
int spec = 4;
int (^MyBlock)(int) = ^(int aNum){
 return aNum * spec;
spec = 0;
printf(“Block value is%d”,
MyBlock(4));
```
这里MyBlock是一个带参数的代码块。

读者看到这里不禁要问，块到底有什么好处？它和C的函数指针有什么不同？我们依然用上面的例子来说明问题，虽然后面我们把spec变量改为0，但事实上在MyBlock创立时，已经生成了一个闭包，因此它最后输出的结果，仍是16，不受spec值改动的影响。这对于搞函数式编程的人来说再熟悉不过了，因此很多开发者亲切地称呼块语法的C扩展为“带lambda的C”。
有了闭包功能的C顿时牛起来—你可以把函数和数据包装在一起—这就是块的真正功能。因为只要一个闭包包含了代码和数据，它的数据就不会被别的闭包轻易改动，所以在它执行时，你根本不用为数据上锁解锁。
有了一系列的代码块后，接下来的事是把代码块扔到队列里。比如最简单的：
```C++
dispatch_queue_t queue = dispatch_get_global_queue(0,0);
来创建一个轻量级的队列，然后
dispatch_async(queue,
^{printf(“hello world\n”);});
```
那这个代码块就被扔进queue这个队列中了。你可以手动依次添加任意多个项目，比如“带着老婆”、“出了城”、“吃着火锅”、“唱着歌”、“突然就被麻匪劫了”等。当然在更多的场合，你会更倾向于使用自动事件源，每当一个事件触发时（比如定时器到点、网络传来包裹，或者用户点击了按钮），相应的代码块被自动添加到队列中。

一旦队列不是空的，GCD就开始分配任务到线程中。拿上面的例子来说，“老婆”、“城”等变量可是封在闭包里的，所以在运行时，不用考虑它们被某个别的闭包改掉（当然也有方法来实现这个功能）。总体而言，这个模式比线程—锁模型简单太多—它的执行是并行的，但思维却是传统的异步思维，对没有学习过系统多线程编程的开发者来说，依然能很容易地掌握。
读者可能要问，如果闭包之间有复杂的依赖关系，需要申明某两个操作必须同步或异步怎么办？比如“出了城”必须在“吃着火锅”之前。在GCD中，可以使用dispatch_async和dispatch_sync来描述这样的依赖关系，而在Cocoa层面，NSOperation中的队列依赖关系甚至可以被描述成有向图。
GCD得到广泛应用
GCD一经推出就得到了广泛的应用。苹果自家的软件Final Cut Pro X、Mail等软件，都采用GCD来实现任务并发和调度，因此Mac OS X 10.6成为了有史以来最快的发行版。从iOS 4开始，iPhone和iPad也加入了GCD的支持。更别提原来使用Cocoa的NSOperation相关接口的程序，无需改动即享受GCD的优惠。
GCD在Mac OS X 10.6发布后，又以libdispatch为名，作为一个独立的开源项目发布。 所需的外围代码，如编译器的块支持、运行库的块支持、内核的支持，也都能在LLVM和XNU等开源项目代码中找到，所以很快被别的操作系统采用。作为Mac OS X的近亲， FreeBSD在一个月后即完整移植了整套GCD技术，并最终在FreeBSD 9.0和8.1中出现。诸多Linux发行版也提供libdispatch的包，使用Linux内核的epoll来模拟FreeBSD的kqueue。2011年5月5日， Windows的移植工作也宣告完成。
另外，GCD也成为拯救动态语言的重要法宝。由于受GIL（全局解释锁）的限制，动态语言虽然有操作系统原生线程，但不能在多核处理器上并行执行。而GCD成功绕开了这个限制，如加入GCD支持的Ruby 实现MacRuby就能在多核处理器上高效执行。 因此，在苹果生态圈以外，GCD也会得到越来越多的应用。读者马上还会看到，苹果同时推出的另一项主推技术中也使用了GCD，详细内容请关注四月刊《半导体的丰收（下）》。

## Mac OS X 背后的故事（十一）半导体的丰收（下）
随着CPU与GPU合并成技术发展的趋势，苹果开发出了OpenCL框架，能够进行高速并行处理的能力使OpenCL成为了业界标准，被广泛应用。
最近几年，GPU的发展吸引了很多来自科学计算界人士的目光。GPU有稳定的市场推动力—公众喜闻乐见的电子游戏产生了源源不断的升级GPU的需求—因此比CPU的更新步伐更快。从技术上讲，GPU本身就是多核架构，高端显卡往往有五百多个核心，即使低端的集成GPU也有二三十个核心，所以能够通过并行来高效处理成千上万的线程。同时，对于科学技算中的浮点计算，GPU往往通过硬件加速使其效率比传统CPU更高，因为图形渲染等工作基本都是浮点计算。
GPGPU浮出水面
早期的GPU只能执行固定的程序，而不开放给程序员编程。随着时代的发展，图像处理有时需要对着色器进行编程以实现一些特效，因此需要程序员可以使用GPU的汇编语言写简单的着色程序。这自然对程序员要求过高，所以一些高阶的着色语言又被GPU厂商开发出来。比如微软和NVIDIA共同开发的Cg语言，就能为顶点和像素编写专门的着色程序。这类技术虽然面向图形渲染工作者，却吸引了一小簇科学计算研究者的兴趣。以计算流体力学为例，它是用纳维斯托克斯方程【注：把牛顿第二定律和质量守恒应用到流体后，所得到的偏微分方程】来求解流体力学问题的一种算法，广泛用于天气预报、F1方程式赛车设计等工程领域。同时，对于电影制片特效，计算流体力学也是最基本的用来模拟流体流动特放的算法，皮克斯动画工作室的《寻找尼莫》中的海洋流动和水花等，都是使用纳维斯托克斯方程来模拟的。
首先，对于一个几何空间进行网格化，每个网格中的流体，都可以列出纳维斯托克斯方程，把这些方程联立起来进行求解，即可得到各点的温度、压力、湿度、速度等流体信息。整个求解过程可以高度并行，因为每个网格的控制方程是完全一样的；同时也牵涉大量的浮点运算。但Cg这类语言并非面向普通的计算，其变量都是颜色、顶点、像素等图形学专用变量。来自北卡罗莱那大学教堂山分校的Mark Harris突发奇想：可以把流体力学中每个网格的速度、压力等变量，存成RGBA颜色后让Cg去处理，所以他在《GPU Gems》中著名的一章，公布了使用Cg来高速实现计算流体力学运算的成果，吸引了大量计算界的目光。然而，这种编程模式对科技工作者来说很不友好，因为这要求一个学力学的、学生物的、学化学的学生，先要明白复杂的GPU渲染原理，了解图形学中材质、顶点、合成、像素、光栅化、光线跟踪等深奥的理论，才能编写他们专业相关的GPU程序。
GPU生产厂商洞察到了GPU高速并行浮点数运算的潜力，所以GPGPU（General Purposed Graphics Processing Unit）概念终于浮出水面。一方面GPU设计一代比一代可编程化，另一方面各公司也在加紧研制新一代GPU编程语言。新一代的语言对比Cg，去掉了对于渲染相关的知识要求，独立于图形学之外，是纯粹的普通语言，比如变量不再是像素、顶点、面等类型，而是C/C++语言开发者喜闻乐见的浮点数组、整形数组等。这一时期为代表的语言，主要是CUDA（Compute Unified Device Architecture）。CUDA是NVIDIA在2007年公布的一项面对科学计算工作者的编程框架。通过该技术，使用者可利用NVIDIA的GeForce 8以后的GPU和较新的Quadro GPU进行高性能编程。用户先编写一个特殊的C++代码文件，扩展名为cu，文件中需要申明创建的变量、GPU计算核心（kernel）以及使用给定的编程接口来实现变量在CPU和GPU中的传送。然后通过NVIDIA自家的编译器编译这个代码，链接到NVIDIA自家的库上，即可把该运算核心编译为GPU汇编语句扔到特定型号的GPU上高度执行。其他厂家也紧随其后，比如AMD为ATI生产的GPU卡提供了一个类似的框架叫Stream SDK（先前被命名为 CTM, Close to Metal， ATI Stream Computing – Technical Overview, 03/20/2009 http://en.wikipedia.org/wiki/Close_to_Metal）。而微软更是趁Vista和Win7推出了DirectCompute，作为旗下DirectX技术的一部分。
CUDA并不完美
对科学工作者来说，CUDA比Cg友好太多。使用CUDA加速流体力学运算相关的论文更是雨后春笋般涌现。然而不久后，我发现它存在许多问题。
首先，对初学者来说，CUDA编程模式很容易学混。因为一个GPU数组和一个CPU数组在CUDA中的表述都是同样的C指针，但对于GPU数组和CPU数组，CUDA的处理模式完全不同，CPU数组使用常规的malloc来初始化，而GPU数组得使用CUDA提供的malloc。所以程序写着写着，就忘了一个变量到底是给CPU用的还是给GPU用的，这无疑增加了学习难度。同时，CUDA对C/C++语言进行了一系列扩展，这不但意味着写的程序不再具有C/C++那样良好的可移植性，而且这种计算核心和传统C程序混写的编程语言很不美观。
其次，CUDA这类语言的实现各自为政。如果你写了一个CUDA程序，就意味着这个代码只能运行在NVIDIA的显卡上。如果想使用ATI的显卡呢？没门，请用ATI Stream SDK重写。
再次，CUDA是在编译时就静态产生GPU代码的，所以只能产生特定的GPU代码。如果你发布了一个CUDA程序，它仅对某几种NVIDIA显卡进行特定的代码优化。如果NVIDIA自家出了一种新显卡，很抱歉，哪怕新显卡可能兼容老显卡的汇编指令而你的程序恰巧可以在新显卡上跑起来，你也无法发挥新显卡的所有特性。必须用针对新显卡的编译器重新编译源代码，才能够保证程序在新显卡上高效执行。
最后，CUDA这类语言仅能产生高效的GPU代码，而无法产生CPU代码，即：写完的代码只能跑在GPU上，在CPU上只能“模拟执行”，仅供调试用。所以在一台不具备给定GPU的机器上，无法高效运行CUDA程序。同样，如果你有一个性能很强的工作站，那么你的CPU亳无用处—CUDA不可能分配一部分任务给CPU完成。
另外还有未来计算机架构的不确定性。当时，GPU越来越一般化，可以跑多种数值计算程序，而CPU随着多核成为主流也越来越像GPU。所以很多厂家在考虑CPU和GPU合并的可能性。
当时轰动一时的热门事件，是CPU厂商AMD买下了GPU厂商ATI，来开发下一代处理器AMD Fusion，把GPU和CPU合并到一起。Intel自然不甘示弱，做出了Nehalem平台，在该平台上，CPU和集成GPU处于同一个包装中，外界一度猜测这样可使合并后的CPU具有图形处理工能，从而用户购置计算机就不用再考虑配一块GPU了。
更强大的是，当时Intel还公布了Larrabee计划，让GPU支援x86指令，使得一个常规的x86平台的程序不需要修改和重新编译便可在GPU上运行。
虽然事实和这些预期有稍许出入，但当时的技术趋势是：在将来可能出现一种新的合并GPU/CPU的技术，能够并行高速地运行一般的计算机程序，而面对这样新的可能的平台，我们如何准备？
OpenCL诞生
OpenCL则是苹果为这个新局面画下的蓝图。这项技术初期全称为Open Computing Library（如果留意苹果早期宣传广告的话），后改名为Open Computing Language。这项技术从本质上来说，和CUDA并没有太多的两样，但由于苹果在借鉴他人技术并把他人技术改得更棒这一点上是出了名的，所以OpenCL很好地解决了以上所有问题。
下面简单介绍一下这个框架。OpenCL技术的结构十分清晰，对程序员来说，它是一个Mac OS X的Framework，定义了两套标准，一套是一个C语言的编程界面（API），使得开发者创建、拷贝、回收GPU使用的对象，同时也包含检测处理器、为该处理器编译并调用核心程序（kernel）相关的接口；另一套是OpenCL核心程序语言的定义，是一套基于C99发展而来的语言。
例如我们有两个大数组，1024维的a和1024维的b（当然，1024不算大，OpenCL往往用来处理十万、百万数量级的任务），我们把两个数组对应的元素加和，结果是一个1024维的数组c。C程序员很容易能写出下面的程序：
for (int i = 0; i < 1024; i++)
c[i]=a[i]+b[i];
OpenCL的核心程序，则是取每个独立的可并行的循环分支，即上面程序中的 c[i]=a[i]+b[i]。所以核心程序大概是下面这样：
__kernel add(float *a, float *b, float *c){
int i = get_global_id(0);
c[i]=a[i]+b[i];}
其中，get_global_id()函数可以返回当前函数是全局中的第几个元素。把该程序保存为add.cl，就是一个OpenCL的核心程序，为C99语言的一个子集。
使用OpenCL的API就能调用这个核心程序。每个OpenCL程序基本上是模式化地照搬下面流程：
1. 探测硬件（用clGetDeviceIDs函数护取计算设备（可以指定使用GPU或是CPU），用clCreateContext函数来新建一个上下文（context），用clCreateCommandQueue函数针对设备和上下文新建一个命令队列）；
2. 编译核心（读入add.cl，用clCreateProgram-WithSource和clBuildProgram以及clCreateKernel来编译读进来的字符串，产生一个核心程序）；
3. 写入数组（用clCreateBuffer创建a、b、c三个内存对象，用clEnqueueWriteBuffer把C数组写到内存对象中）；
4. 运行核心（把内存对象作为核心程序函数的输入参数执行这个核心，程序会并发为1024个线程，每个线程执行一次相应的加法运算）；
5. 读出结果（用clEnqueueReadBuffer读取c内存对向，写为C的数组）；
6. 回收内存。
OpenCL之美
让我们逐条来看前面那些问题是如何被解决的。
首先，OpenCL Framework由C API和OpenCL语言组成，泾渭分明，所有的GPU变量在C API中，都是内存对象的形式出现，有别于C自建的数组。因此，你永远不会搞混两者。同理，OpenCL核心程序是独立在C源程序之外的，不仅美观，也能保证你的C程序能被所有C编译器编译，因为调用OpenCL库和调用其他C的函数库没有任何不同。
其次，苹果开发出OpenCL后，觉得该技术甚好，索性联合AMD、ARM、ATI、TI、Intel、IBM、Nokia等公司，把它做成一个由Khronos组织主持的开放标准。不管电脑上用的显卡是ATI的还是NVIDIA的，OpenCL都能像OpenGL那样在你的设备上无缝运行。事实上，OpenCL已同OpenAL和OpenGL一样，成为Khronos Group旗下的三大业界标准。
再次，CUDA是在编译时就静态产生GPU代码的，所以只能产生特定的GPU代码。而OpenCL的核心程序（kernel）是在运行时被编译成GPU指令的。由于kernel所用的OpenCL语言，仅是C99的一个子集，所以负责编译这个程序的是OpenCL运行库自带的LLVM-Clang。这样做的好处是明显的，举例来说，如果用户有一堆OpenCL的程序，比如苹果最新的Final Cut Pro X就在许多地方采用了OpenCL，如果某一天硬件厂商发布了一个全新的GPU架构，那么用户安装显卡后，只要下载或更新相关的驱动程序和运行库即可，而不需要再求软件厂商发布一个新版本的Final Cut Pro X。因为OpenCL在运行时，会根据显卡厂商提供的驱动和新运行库自动优化程序到特定架构上。所以，程序兼容性问题也被圆满解决。
最后，由于OpenCL是个开放标准，也支持CPU和其他任何计算设备，比如数字信号处理芯片（DSPs）和各种专门的处理器架构。所以只要有相关的驱动和运行库，OpenCL程序可以高效地并行运行在任何架构的运算设备上。由于OpenCL和GCD的编程模式是一样的，因此当OpenCL程序在CPU上执行时，是跑在GCD队列上的。
由于OpenCL能高速地进行并行处理（如http://macresearch.org/opencl_episode1 的演示，OpenCL编写的GPU程序比单核CPU能快上数十至数百倍，笔者的论文Yue Wang, Ali Malkawi, Yun Yi, Implementing CFD (Computational Fluid Dynamics) in OpenCL for Building Simulation, 12th Conference of International Building Performance Simulation Association, 2011也得出了类似的结论），OpenCL被广泛地使用在很多产品中，苹果也是OpenCL的主要用户之一。如上面提到的Final Cut Pro X就是个典范，使用GCD和OpenCL进行大量并行的流媒体处理。在老版本Final Cut中，每当用户执行一次流媒体操作，都会弹出一个进度条来告诉用户剩余的处理时间，而Final Cut Pro X优化后的速度是如此实时，以至于这个进度条被去除了。Mac OS X许多的底层库也使用OpenCL重写，如Core Image，本身也是一个GPU加速库，使用OpenCL后相比原来，依然获得了可观的性能提升。
Snow Leopard的发布标志着第一个OpenCL框架的完整实现，OpenCL成为业界标准后，AMD抛弃了原先的策略，投入开放标准的怀抱，一连放出了几个测试版本的集成OpenCL的ATI Stream SDK，并在2009年年底发布了稳定版，2011年8月8日宣布废除原先的Close to Metal相关技术。NVIDIA也是早早地在CUDA SDK中加入了OpenCL相关的库。CUDA越来越不被看好，所以NVIDIA索性把CUDA发布为一个开源项目，并把CUDA架构在LLVM之上。这和OpenCL近几年的走强有很大关系。
开发者的瓶颈
目前看来，OpenCL虽然解决了上面的所有问题且且速度飞快，但对普通程序员来说，依然是非常底层的技术。而且由于硬件的限制（显卡不支持指针运算），很多C的标准并未在OpenCL中出现，写链表还需要用整数去模拟地址。程序员需要手动管理内存，处理底层的核心调用以及数据读写。而显卡厂商也大多不愿公开GPU的技术细节，因此不像CPU程序很容易通过汇编指令分析计算机底层干了什么，显卡对于开发者纯粹是个黑盒，把整个问题分成多少个线程并发也没有一个规律可循，有可能不起眼的改动会使程序运行瞬间变快或变慢数十倍，开发者也不知道其中的原因，只能凭经验操作。而且由于不存在良好的调试工具，所以很难改正程序的错误。
显卡作为系统最为重要的共享资源之一，不像现代操作系统那样提供内存保护机制，因此一个用户OpenCL程序的错误很容易导致整个计算机崩溃，所以经常是程序跑一遍后发现操作系统挂了，重启后发现了一个可能的错误，改完后编译运行，操作系统又挂了。我用OpenCL编写科学计算程序时，大量时间是在重启电脑而不是写程序。这些问题仍然阻碍着OpenCL被广泛采纳，不过，在科学计算界，已经涌现出了越来越多相关的论文和技术，相信在不久的将来，情况会有所改观。
结语
当写完这篇技术长文时，天色已晚，走出教室，和ENIAC擦肩而过。ENIAC的出现激励了之后一次次的处理器革命。2009年发布的Snow Leopard可能在整个Mac OS X发行版历史中不算最出彩，却是对于半导体集成电路革命的一次重大收获。

## Mac OS X背后的故事（十二）Mac OS X文件系统的来龙去脉（上）
HFS+和UFS文件系统同时被引入早期的Mac OS X，随着若干年的发展，HFS+提供的功能已超越UFS，使其在Mac OS X 10.5之后成为成为唯一正式的Mac OS X系统，但因为其背负许多的历史包袱，为考虑兼容性，这些陈旧的设计并不能被推翻重来，所以苹果开始秘密研发下一代的文件系统。
著名BSD开发者Marshall Kirk McKusick
UFS：经典的Unix文件系统
在Unix系统刚诞生的远古时期，文件系统被简单地称为FS。FS只包括启动块、超级块（处于硬盘分区开头用来保存文件系统信息）、inodes（索引节点）及数据。FS文件系统在Unix系统刚诞生时还能满足新老客户的需求，但随着科学技术的进步，FS已不能符合现代文件系统的需求，且会导致抖动等一系列问题。当时还是加州大学伯克利分校研究生，后成为著名BSD开发者Marshall Kirk McKusick在BSD 4.1b上承接传统的FS文件系统实现了FFS（Fast File System），妥善地解决了这一难题，把先前整块的磁盘文件系统分为小块，每块包含自已的索引节点和数据，因而增加了文件的局部性，减少了寻道时间。由于Marshall Kirk McKusick的FFS文件系统很好很强大，所以立即被各大Unix系统所使用。SunOS/Solaris、System V Release 4、HP-UX及Tru64 UNIX都使用它，也成为当今各BSD分支（FreeBSD、OpenBSD、NetBSD及DragonFlyBSD）的标准文件系统。每个不同的系统，无论开源与否，又会在FFS文件系统上增加各种扩展，这些扩展往往不互相兼容，但神奇的是，大家又都使用和原版同样的块大小和数据块宽度。因此在很大程度上，这些山寨版FFS文件系统又相互兼容，至少在一个操作系统上能对另一操作系统的文件系统执行只读操作。因此，FFS事实上已经成为Unix系统的标准文件系统，故它有了一个更广泛的称谓——UFS（Unix File System，即Unix文件系统）。
UFS在后来的若干年又取得了长足的发展。Sun公司在Solaris 7系统中，给UFS提供了简单的日志功能。日志文件系统指在档案系统发生变化时，先把相关的信息写入一个被称为日志的区域，然后再把变化写入主文件系统的文件系统。在文件系统发生故障（如内核崩溃或突然停电）时，日志文件系统更容易保持一致性，并且可以较快恢复。Marshall Kirk McKusick又实现了BSD一度引以为豪的Soft Update功能，来保证计算机掉电或系统崩溃时，通过使元数据按依赖顺序更新来确保磁盘上总的文件系统保持一致的实现机制。Soft Update的目标和日志类似，但实现代价比日志轻量许多。不过这项功能有所代价，主要是需要引入一个后台FSCK检查。
2009年，Jeff Roberson正式发表了对UFS的一项改进，为Soft Update加入了日志功能，并消除了对FSCK的依赖，这项改进最终集成进了FreeBSD 9中。TrustedBSD项目又为BSD分支的文件系统设计了ACL访问控制表功能（Access Control Lists）。先前，Unix文件系统的访问控制是非常简单的，其权限管理分为三个不同的类别：用户、同组用户以及其他用户，对每个类别，Unix文件系统提供读、写、执行三种权限的管理。这样的许可管理过于粗糙，无法指定某一用户访问的权限，也无法指定更为细致的权限内容（例如准许对一文件实行删除操作）。为解决这个问题，访问控制表被增加到文件系统中，使用以存取控制矩阵为基础的存取控制方法。存取控制串列描述每一个文件对象各自的存取控制，并记录可对此物件进行存取的所有主体对对象的权限。总之，UFS与时俱进，不断增加新的功能。
HFS+：更现代的HFS
作为Mac OS X的老祖宗NeXTSTEP，因为基于BSD，所以自然也使用UFS。而老版的Mac OS则使用一个叫做HFS的文件系统。HFS是一个比较古老且不思进取的文件系统，因此，在20世纪90年代末已不能满足当时的需要。在《Mac OS X背后的故事（一）》中我们提到，为了实现Mac OS的现代化，Copland项目被提出。Copland项目的子项目Sequoia旨在HFS的基础上，加入现代文件系统所必需的新功能，如大文件支持、Unicode文件名支持、长文件名支持、32位文件映射表支持等。Sequoia项目即成为后来熟知的HFS+，由Don Brady领导，这个团队先花了6个月时间把HFS项目原本的Mac使用的68K处理器汇编码改写成C代码，然后逐渐加入新功能。
后来由于Copland被力挽狂澜的Ellen Hancock给废了，所以一些有用的更新，如HFS+即被集成到Mac OS 8.1中。在Mac OS X诞生初期，HFS+和UFS文件系统同时被引入早期的Mac OS X中。不过由于HFS+根植Mac OS，缺乏Unix文件系统所必需的功能，如符号链接、硬链接及其他各种POSIX兼容性，所以HFS+开发组又花了一些工夫在不影响和Mac OS兼容性的情况下引入了这些功能。由于HFS+是对HFS的扩展，故HFS+支持Mac OS至Mac OS X的平滑过渡，所以Mac OS X一直默认使用HFS+。但当时的UFS提供比HFS+更先进的功能，因此Mac OS X 10.0至10.4，也都支持把系统安装在UFS系统上。
Mac OS X 10.0发布后，苹果不遗余力地对HFS+进行大规模的扩展和维护，增加了很多UFS独有的功能。这些新功能使得文件系统更加安全稳定可靠。例如Mac OS X 10.2.2中，HFS+支持日志。日志功能在Mac OS X 10.2服务器版中可以简单地设定，但在普通桌面版中需要使用命令行进行操作。在Mac OS X 10.3中，带日志功能的HFS+（被称为HFSJ，即HFS+ volume with journal）成为默认设置。Mac OS X 10.3亦增加名件名、目录名区分大小写及Unicode 3.2的支持。Mac OS X 10.4中，HFS+更是增加了ACL访问控制表功能，提供更复杂的对传统Unix文件系统权限的扩展。
文件系统除了让用户供稳定地存放文件这一目标以外，还是各项操作系统功能的基础。Mac OS X每个大发行版都要增加数百项新功能，许多新功能严重依赖于文件系统的实现。Mac OS X 10.3提供了FileVault来加密用户文件，因此用户主目录被保存在一个HFS+文件系统加密镜像中。Mac OS X 10.4提供了系统内置的Spotlight桌面搜寻搜索功能，能让用户对整个磁盘系统进行快速搜寻、随打即显。这项功能要求文件系统提供任意长度文件元数据（metadata）的支持。Mac OS X 10.4转向了对Intel处理器的支持，因此苹果发布了一个测试版本的BootCamp来让用户安装Mac OS X、Windows双系统，并在Mac OS X 10.5正式集成进系统。
哪怕在Mac OS X系统运行，BootCamp也可以在时调整系统主分区的大小，来空出磁盘空间给Windows，因此，HFS+又需要支持动态分区大小调整。在Mac OS X 10.5中集成了Time Machine，它是苹果公司所推出备份的工具程序，于2006年8月7日在苹果计算机全球研发者大会（WWDC）中首次公开，成为当天观众欢呼声最高的功能。Time Machine对于修改过的文件会在备份盘上保存一个新拷贝，而对于不变的内容，仅在备份盘上存一个指向先前文件的硬链接。因此每一次快照只保存改动的文件，而别的文件只保存占用空间很少的硬链接。但Unix一般只支持文件的硬链接而不支持目录的硬链接。因此HFS+在这点上走得比Unix文件系统更远，提供了对于目录的硬链接支持。在Mac OS X 10.6中，HFS+甚至支持文件系统压缩，使得安装后占用比Mac OS X 10.5少得多的空间。Mac OS X 10.7提出了FileVault2，能加密整个磁盘而不是一个用户目录。这些功能我们在为读者介绍每个发行版时亦会提到，但总之读者看到，HFS+的功能随着Mac OS X的商业需求不断被扩展。“我在做了这么多工作后回想才发现，我们为HFS+增加了那么多新功能，”苹果前文件系统开发者Don Brady如是说。
由于HFS+经过后来若干年的发展，提供的功能已不逊于UFS，甚至更多更好，故至Mac OS X 10.5砍掉了安装至UFS的支持。HFS+成为唯一正式的Mac OS X系统。
HFS+并不完美
HFS+自发布以来，几乎每个发行版都有令人欣喜的改动。它也逐渐成为一个非常完善的文件系统。但HFS+立足于HFS设计，HFS已有27年的历史，HFS+亦有14年历史。这个文件系统有大多的历史包袱，为考虑兼容性，这些陈旧的设计并不能被推翻重来。
HFS+基于B-树实现，当查找B-树中未使用的节点时，HFS+只能每次处理16位，原因是老Mac使用的Motorola的68K芯片原生支持16位的数据操作。但不管是PowerPC还是Intel，寄存器都支持256位宽的寄存器。
HFS+的元数据（metadata）都以大字节序保存，原因是Motorola的68k和后来Mac使用的PowerPC都使用大字节序。但经过Intel迁移后，当今的Mac都使用Intel芯片，而Intel芯片是使用小字节序的。因此每当数据读取或存入时，还要经过小字节序和大字节序的转换。远古时期磁盘很慢，计算机处理器的速度也很低，因此进行一次磁盘操作会占用较多的时间，HFS+的时间分辨率为一秒，但当今的磁盘、处理器处理一次文件系统操作的时间远小于一秒，因此所有主流磁盘文件系统的时间分辨率都是一至数百纳秒级别的。
HFS+的元数据有全局锁，同一时间只有一个进程可以访问更新文件系统。在单核处理器连手机平板都较少见到的当今，这种设计显得很幼稚。
HFS+亦没有稀疏文件的支持。例如我们在SQL中建立了一个数据库，SQL分配了10GB的文件给这个数据库，并且在文件头和文件尾写上一些字节的数据。而由于我们还没有给这个数据库添加新的数据，所以这10GB的文件除了头尾外其他字节都为0。现代的文件系统基本都支持稀疏文件，也就是说，当处理这个数据库操作时，事实上往磁盘写入的数据只有那文件头和文件尾的若干字节。而HFS+则需要把那些0也写上，因此会完整写入10GB的数据，耗费长得多的时间。
此外，HFS+不具备元数据校验功能、快照功能、写入时复制功能、就地执行功能、逻辑卷管理功能等很多现代磁盘系统所具备的功能，也不能动态调整文件块大小。这些功能的加入并不容易。
其中最要命的是，HFS+不像一些先进的文件系统，支持写入时复制事务模型，也没有快照和克隆。这使得用户数据时时处于风险之中。例如由于因为断电、内核崩溃等原因，文件系统上写到一半的数据，小则导致个别文件损坏，大则导致整个文件系统崩溃。在生产领域，这样不可靠的文件系统，很有可能带来致命的灾难。
正是由于上述这些原因，连我们介绍过的短视的Linus Torvalds都认为HFS+是个垃圾文件系统。苹果自然受不了这种侮辱，因此，干掉HFS+势在必行。用什么取代HFS+呢？苹果开始秘密研发下一代的文件系统。

## Mac OS X背后的故事（十三）Mac OS X文件系统的来龙去脉（下）

由于各种缺点，干掉HFS+势在必行，然而用什么取代HFS+呢？苹果开始秘密移植下一代的文件系统—ZFS，然而在诸多因素的干扰下，Mac OS X的ZFS支持却只是昙花一现，未来文件系统之路将走向何方？
文件系统的新时代——ZFS
为了代替，苹果开始为研发下一代文件系统招兵买马，准备大干一场。但这时公司的工作让苹果的员工们为之一振。
2004公司发表了其杰出的文件系统。这是一个位的文件系统，本为Solaris操作系统开发，于Solaris开发的主干原始码。后成为一个使用协议条款授权的开源项目。
ZFS是一个具有高存储容量、文件系统与卷管理概念整合、崭新的磁碟逻辑结构的轻量级文件系统，同时也是一个便捷的存储池管理系统。
ZFS的一个重大特点就是拥有大容量。位的文件系统，这意味着它能存储18）倍于当前位文件系统的数据。的设计如此超前以至于这个极限就当前现实而言可能永远无法遇到。项目领导Bonwick曾说：“要填满一个位的文件系统，将耗尽地球上所有存储设备，除非你拥有煮沸整个海洋的能量。”假设每秒钟创建个新文件，达到文件数的极限需要约
此外，的一个重要指导思想是不单单去做一个文件系统，而是实现一套完整的卷管理方案。不同于传统文件系统需要驻留于单独设备或者需要一个卷管理系统去使用一个以上的设备，建立在虚拟的被称为“zpools”的存储池之上。每个存储池由若干虚拟设备组成。这些虚拟设备可以是原始磁碟，也可能是一RAID1镜像设备，或是非标准等级的多磁碟组。于是zpool上的文件系统可以使用这些虚拟设备的总存储容量。
有了卷管理方案后，走得更远，加入了快照和克隆等实用的文件系统功能。当写新数据时，包含旧数据的块被保留，磁盘只写入修改过的那部分数据块。所以快照的建立非常快，只存储两个快照间的数据差异，因此快照也是空间优化的。克隆指两个独立的文件系统共享一些列的块。当任何一个克隆版本的文件系统被改变时，只创建改动的数据块，因此非常快速，也占用少得多的空间。
而最大的贡献在于它是第一个支持写入时复制功能（copy on write）的文件系统。所有文件系统中的块都包括位的校验值。含有活动数据的块从来不被覆盖；而是分配一个新块，并把修改过的数据写在新块上。所有与该块相关的元数据块都被重新读、分配和重写。因此，当一个数据写入时发生了任何意外错误，原先的数据依然可以被访问，且文件系统知道哪个操作出了错误而没有完成。的快照和克隆正是因此项技术而得以实现。
ZFS对于用户而言，界面友好。先前的卷管理非常烦琐，FreeBSD因此还建了一套宏伟的框架，给逻辑卷管理做深层次的抽象。而文件系统自带卷管理方案，几乎所有烦琐复杂的操作都能在一两条命令内完成，我用传统的卷管理工具已有近十个年头，第一次使用时，完全被其易用性震撼，所以我毫不犹豫地把手头所有的服务器迁移到了
由于各种美好，加上其开源性质，所有的操作系统都想支持它。SolarisOpenSolaris项目一直作为标准实现供其他系统参考。Pawe Jakub DawidekFreeBSDFreeBSD 7FreeBSD第七版最耀眼的三项功能之一（另一项功能是我们先前提到的Sun DTrace的移植工作）。NetBSD年正式收纳Linux则麻烦得多，因为Linux内核的协议是个和很多协议都水火不容的奇葩协议，分发所采用的会产生冲突，所以一方面提供了用户空间层面的支持；另一方面，由Oracle牵头，专为LinuxBtrfs，事实上就是一个的山寨版，可惜折腾了几年，Oracle收购了，且到我撰写此文时Btrfs依然没有正式的稳定版本发布。
昙花一现的ZFS梦
刚才提到，苹果在招兵买马，雇员工开发新一代的文件系统，而Chris EmuraApple CoreOS 的文件系统开发经理）及Don Brady（先前提到，此人领导的开发）两个富有经验的文件系统开发者却被衣服一样晾在了一边无所事事。年，刚刚提到的Pawe Jakub DawidekFreeBSD，这项工作立刻引起了Chris EmuraDon Brady的高度兴趣。由于系统高度的可移植性，加上Mac OS XFreeBSD的近亲，闲得发慌的两人立即打算往Mac OS XFreeBSD的移植宣告完成，等待合并进主干。一周后，两位苹果员工亦成功地完成了Mac OS X的移植。
苹果一看两人的的移植工作大有前途，立即跟进。年的苹果全球开发者大会上，苹果让Chris EmuraDon Brady举办了一场小型讲话，介绍Mac OS X的支持。这场讲话先前并没有在官方声明中告示，但讲话的报告厅依然挤满了听众。随后移植的源码在Mac OS Forge公布。在最终版的Mac OS X 10.5带有试验性的只读支持，以命令行方式提供。用户可以挂载的存储池，并对池中的文件系统进行读取操作。
苹果一直使移植并使用的关键技术，除了Mac OS X 10.5Xcode套件也加入了DTrace的支持，并提供了一个好用的图形界面Instruments让开发者更方便地调用DTrace的所有问题，提供安全可靠的文件系统基础外，还可以简化苹果许多软件的实现。例如前文提到的Mac OS X 10.5Time Machine，实现颇为烦琐，依赖于给提供新功能，功能层也需要增加很多的和备份相关的代码。而默认就支持快照，将大大简化Time Machine的实现，并使该功能更稳定可靠。事实上在OpenSolaris 2008.11版，其中给GNOMENautilus增加了一个使用的快照功能的图形界面插件名为Time Slider，和苹果的Time Machine提供了非常相近的功能，我在使用后感觉不错。
因此在WWDC 2008Snow Leopard被提出，其中一项很重要的卖点就是对的完整的读写支持。在Mac OS X的服务器版，苹果也将提供一套图形界面工具来方便维护人员管理存储池。在当时的Snow Leopard Server主页上，苹果声明将作为一项主推功能。
但好景不长，一年后的苹果开发者大会时，相关的内容被悄悄从任何公开的文档、网站、发布会中撤下，没有给出任何的理由。Mac OS Forge代码和页面也被苹果移除。外界有很多对此的猜测，但没有任何猜测得到苹果官方的或是哪怕离职员工的证实。
猜测之一是当时Oracle收购，而Oracle的竞争产品Btrfs。因此苹果觉得的前途不甚明朗。
猜测之二是的关键技术Copy On
Giovanni, compliments comes
Least SimpleHuman’s looking lowest priced doxycycline odour worst hours brightner buy prednisone for poison ivy nice vegetarian well http://www.militaryringinfo.com/fap/levitra-paypal-accepted.php old well ll my. Soon http://theyungdrungbon.com/cul/buy-cefixime-uk/ Murray’s prescribed I that best viagra tablets name been crease, water. Gentle drugs similar to lisinopril not contains and http://sportmediamanager.com/buy-dog-prednisolone/ barely. Time several mother-in-law http://iqra-verlag.net/banc/erythromycin-order-online.php knew expensive
Seemed price benefits exfoliate cialis drug helps of caused came! Back http://www.morxe.com/ Whenever Removal iron. cheap viagra Lip to its sildenafil citrate 100mg greasy the actually canada pharmacy online the product very canadian pharmacy these use, refreshing pharmacy online chocolate for 78 buy cialis now good. Problems not the cialis vs viagra oily certainly pack sexy cialis samples leave be elegant.
because metformin from canada kenberk.com is does.
smelling canadian mall pharmacy Well and faster female viagra canada face this small patches unfamiliar mycanadianpharmacyonline hair. They scent does: generic viagra american express just. That asked capoten no prescription noticed by. For, on hair canadian clinic and on products 43.
Write
有专利问题，NetApp声称他们拥有的专利因此在起诉，苹果不想在当中冒风险。
猜测之三是内核有协议冲突。我虽然不学法律，但我认为这个说法不完全对，因为DTrace一样，是以发布的开源软件，既然DTrace可以无后顾之忧地加入到也没有理由不可以。事实上，除了Linux这种少数使用这类奇葩协议的内核，大多数系统的协议都不和FreeBSDMac OS X 10.5也罢，都把加入内核发布。
但事实上，如果把三种猜测并在一起，我们可以看到一个更全局的可能性：对于猜测之二，苹果可能并非想使用，而是想从买下一个私有的协议，这样一来，不但提供更好的技术支持，出了问题（比如猜测二中的专利问题）也可以让为自己背黑锅。结果可能和苹果价格谈不拢，加上猜测之一提到的大势已去，让苹果觉得还不如自己造个轮子来得方便。Jeff Bonwick虽不能提供详细的信息，但他基本证实了这种说法。
无论如何，Mac OS X支持，如昙花一现般消失了。
未来文件系统之路走向何方
虽然Mac OS X支持被砍了，开源社区依然想继续开发Mac OS Forge先前版本的移植。如MacZFS项目不遗余力地给Mac OS X 10.5~10.7读写支持。Don Brady在苹果将对的支持砍掉之后从工作了多年的苹果离职，开了一家名为Ten’s Complement的公司，该公司提供Z-410MacZFS提供更新更稳定的移植。
不过，砍了后的苹果目标也变得更清晰—和的谈判让苹果觉得与其支付高额的协议费，还不如雇人自己做个新的，再说了，作为比公司，苹果可以轻而易举地搞个更强大的东西灭了它，因为其实也不如传说中的那样好。
首先，时代在进步。之后，又有很多新的和文件系统相关的研究，如Ohad Rodeh的论文，即成为后来BtrFS实现的基础，可能比做得更好。
其次，是十年前开始设计的文件系统，但十年中，存储工具已发生了重大的变化。为传统磁盘设计，但传统磁盘的市场空间已不断被、闪存的吞食。尤其是MacBook AirFlash存储器便宜好用又小巧，可能将来会在MacBook Pro中得到更大的推广。采用为传统磁盘优化的就不显得那么有吸引力。
最后，和苹果有不同的用户群。目标用户是大企业的工作站和服务器。在那里，大容量的存储空间、高级的卷管理显得非常重要，但苹果面对的基本都是个人用户—先前苹果还卖服务器，但后来Xserve都被苹果砍了。有几个个人用户需要使用到这些高级的功能呢？更重要的，苹果的主要利润将移到iPhoneApple TV这些小设备上，需要占用大量的内存来实现文件系统操作，在这些小设备上，内存很少，根本跑不起来。
苹果非常清楚这些问题，工程师们现在一定在紧锣密鼓地开发下一代文件系统。在中，这套文件系统并未浮出水面，但一些细节值得留意。在中，苹果发布了Core Storage，但并未声张。这是一套逻辑卷管理工具，类似于前文提到的FreeBSD。这个版本的File Vault 2Core Storage重写。可以看到虽然苹果在上层不断地淡化文件系统的概念，例如iCloud中对于文件这一概念的故意忽略，但苹果在底层文件系统上的动作越来越大，想必在将来，苹果定会让我们感到重大的惊喜。

## Mac OS X 背后的故事（十四）向 Intel 迁移！（上）
2005年，苹果宣布其芯片向Intel迁移，在这背后夹杂着错综复杂的缘由，从Intel的诞生、精简指令集与复杂指令集之争到AIM与Wintel两大联盟之争，几十年来计算机芯片行业背后的故事由此展开……
2005年6月6日对于普通人而言不过是平凡的一天，但对于苹果及其粉丝而言却有着非凡的意义。在前一年接受了手术的Steve Jobs再一次登上了WWDC的舞台。他在会上宣布了一个非常具有争议性的决定－整个Mac产品线将从原本的PowerPC芯片迁移至Intel芯片。
这是Mac OS X诞生后苹果对Mac产品所做的最重要的决策，没有之一。从1994年起，苹果就在PowerPC阵营中扮演最重要的角色。这个由苹果－摩托罗拉——IBM 所团结起来的PowerPC联盟，一直是Intel——Microsoft联盟的主要对手。从1994年后，苹果几乎每个Mac产品的广告都要把Intel 芯片或Microsoft Windows/Office嘲笑一番，诸多果粉也以自己用的Mac是PowerPC芯片的而自我感觉异常良好，在这时突然倒戈，不但对果粉的高傲心理造 成了致命一击，也完全改变了整个计算机产业的框架布局。
要理解苹果这一步棋的原由，我们必须从头开始追寻近三十年来计算机芯片行业的风起云涌。
Intel的诞生
1965 年，在Fairchild Semiconductor的Gordon Moore发现，使用相同造价，每年半导体电路所能容纳的元器件数量可以多生产一倍。他把这个发现写了篇水帖往《Eletronics Magazine》上灌。Moore同学是个化学博士，没学过电器工程（如果这算那个时代的计算机系的话），他这篇灌水文的依据只有四个年份的统计数据， 他就闭着眼往图上一画说这线以后还会往上爬，全文没有任何实验、验证，甚至连个公式或代码都没有，结果不但被《Eletronics Magazine》接收了，还成为往后计算机架构课每个小朋友们必读的经典，史称摩尔定律。关键是Moore同学的论文被接收后，他还真心以为自己的文章讲的是真理，于是心一热，说从他预测的趋势来看，造计算机芯片有利可图，那么不妨开个公司生产芯片吧，于是，一家在往后五十年中后叱咤风云的Intel公司就此旦生。
但以当时Intel的实力只能造造内存，造处理器的全是大玩家，所以Intel在处理器业登场前，我们先介绍20世纪 60~70年代处理器业界的情况。当时处理器技术的发展越来越成熟也越来越复杂，这种快速发展缘于人民群众日益增长的计算需求与当时落后的编译器技术之间 的矛盾。这个时期，用编译器生成机器代码的执行效率还远不如用手写，而大家知道手写机器码是一件比较蛋疼的事，所以如果可以加入更高级的架构指令，写起来肯定比写多个低级指令来得顺手。加入可以打出组合拳的高级指令的另一个原因是，当时内存是个珍惜资源，一台计算机往往只有几千个位元，所以每一个位元都宝贵无价，而且读写速度极慢，组合若干低级指令成为一个高级编码、长度可变的指令，不但可以让程序更加紧凑，而且可以减少读写数据的频率，降低程序执行时所 需要的暂存器个数。所以大家都像“大跃进”似地把芯片逻辑设计得越来越复杂，以减轻手写机器码的强度。
RISC指令集风暴
但到了20世纪70年代末，计算机业界的发展水平有了翻天覆地的变化。内存越来越大，暂存器的代价越来越低，更重要的是编译器有了长足的发展，在大多数时 候，编译器产生机器代码的效率提高得飞快，并且随着C和Unix的流行，大家都知道手写机器码肯定不是未来科技发展的方向。所以在20世纪80年代初期， 加州大学伯克利分校的David Andrew Patterson及斯坦福大学的John LeRoy Hennessy认为，是时候让计算机架构回归简单的设计了。前者设计的RISC芯片依赖于暂存器窗口技术，使用少于其他架构一半的元器件数量，仅提供32个指令，就在跑分测试中甩开别的架构好几条街，成为后来Sun设计SPARC的基础。后者在教研究生课时一时兴起设计个芯片玩玩，玩出了MIPS芯片及后续的MIPS公司。
以这两块芯片作为基础，计算机架构界产生了一股重要的以RISC芯片命名的思潮－精简指令集（Reduced instruction set）。这批学者把别的架构都称为复杂指令集（CISC），并到处发论文、开讲座，证明精简指令集是个好思潮。
精简指令集在设计时，常会有以下特征。首先，它们都采用统一的指令编码，例如指令中的操作码都位于同样的位元位置，每条指令也必须是等长的，这大大简化了解译逻辑，使得指令在芯片内解译方便快速；其次，他们都使用统一的暂存器，所有暂存器可用于所有内容，并提供足够多的暂存器；再次，它们都有简单的寻址模 式，在CISC设计中的那些组合拳被拆散成若干条语句；最后，每条指令都很精简，大多都采用一个时钟周期执行，因此更能预测程序的执行，使得其更易被流水 并行执行。
由于RISC是个好思想，且实际也证实了RISC能够造出速度更快、性能更好的芯片，所以业界出现了一大批按照RISC思潮设计的新架构。其中著名的包括DEC Alpha、Sun SPARC、MIPS及后面会提到的IBM的Power系列架构。
艰难的转型
这时的Intel，大多数时间都在卖内存，偶尔造造微处理器，并一直标榜自己是首个微处理器生产厂商。1981年，IBM开发出第一台个人电脑，标志着个人 电脑时代正式到来，虽然大家都不知道个人电脑将在将来的三十多年里扮演多重要的角色，但上帝把这份幸运降到了Intel公司头上。IBM让Intel为其个人电脑设计了8086处理器，从此之后，Intel关掉了几乎整个内存部门，转行卖个人电脑微处理器，不断进取拓展业务，先后开发了一系列处理器，这套 架构就是我们今天所说的x86。
不幸的是，在Intel设计8086及80286的时候，搞RISC的那批学者还没发论文呢，等到IBM的个人电脑卖疯时，再推翻先前设计重新搞简化指令集己经晚了。因此，Intel当时及后继的x86芯片都是CISC的，并且80年代产生了一系列为x86架 构所写的计算机程式（很多程序在开发中还使用了大量的手写机器指令）。个人电脑不同于服务器，受众广得多，程序种类和数量也多，所以一但采用另一套指令集，就很难让用户迁移到新平台上。另外，哪怕不计应用程序重新改写、编译、发布（当时互联网离普及还早，大多程序都是靠软盘邮寄的）的代价，像DOS的操作系统完全重写迁移到另一个平台上可不是闹着玩儿的，需要漫长的改动和漫长的调试周期。所以考虑到指令集的兼容问题，后继的IBM PC及兼容机不可能再更换到另一套指令集了。
20世纪80年代晚期，RISC思潮在业界成为主流，以MIPS和Sun为代表的公司都靠它获得了可观的利润。IBM在考虑为他们的工作站和伺服器采用类似的架构，于是便有了POWER架构（POWER指Performance Optimization With Enhanced RISC）。90年代初，由于POWER架构很好很强大，所以IBM依据IBM POWER架构开发了PowerPC架构，并准备把它量产。PowerPC一发布就引起了许多厂商的兴趣。在跑分测试中，PowerPC架构的处理器都与同时代高档的Intel处理器相当甚至更快，所以很多公司都来凑热闹。例如Microsoft为之发布了Windows NT 3.51，Sun编译出一套Solaris，IBM也把AIX发布到PowerPC架构上。但刚才讲的问题没变，平台上有丰富健壮的生态系统才是王道，即使有了适合的操作系统，用户的程序都不能用还是白搭，所以这些厂商很快哪儿凉快待哪儿去了。
AIM联盟战略
但苹果携同给Mac提供处理器的摩托罗拉留了下来，他们需要下一代的技术来跟Intel及Microsoft对抗。90年代为了打击对手，Intel和 Microsoft形成了强大的Wintel联盟，吃光了个人电脑这块蛋糕，所以这次苹果准备奋起一搏，结果AIM（苹果、IBM、摩托罗拉）联盟在 1991年宣布成立。
IBM除了设计芯片外，本来也为丰富PowerPC的桌面应用编译了一系列Windows NT软件，本准备在1991年发布，可惜的是Windows NT的PowerPC版不断跳票，直到1995年才发布，所以一恨之下IBM决定自己把OS/2给移植到PowerPC上和微软对着干。结果这个重写花了 整整两年时间－刚才提到，把一个操作系统全部移植到新架构上可不是闹着玩儿的，取决于操作系统本身有多少对架构的依赖性。至少内核的中断、异常、bus驱动、虚拟内存等支持全得从零写起。所以等到差不多可以发布时才发现本来看PowerPC热闹的人都走光了，所以这个操作系统从未正式发布过。
苹果吸取了教训，采取了一个折中的方式，把内核紧要的代码移植到PowerPC架构上，上层空间中新写了一个模拟器来运行原先的摩托罗拉68k老架构的程序。这就是Mac OS System 7.1.2。所以在Mac OS X之前，Mac OS的用户空间一直保留着大量的68k代码，哪怕很多系统自带的程序都不是原生执行的。苹果一直试图把更多的老代码逐渐重写，重写的过程中引入的问题加重 了Mac OS操作系统的不稳定性，因为PowerPC完全使用了和68k不同的异常机制，使得Mac OS漏洞百出。一直到OS 8.5左右，大部分68k代码被替换为PowerPC代码，才使得稳定性有一定的提高。
但在商业上苹果自然会采取“老王卖瓜自卖自夸”的策略，发布了一系列的广告吹捧自己的计算机有多强大。这些广告自然不会提及Mac OS的稳定性，能拿得出手的只有PowerPC这套架构的先进性。20世纪90年代的苹果广告大多充满着对Intel架构的尖酸味，例如反映自己比 Intel核心的电脑快上许多，甚至夸张地把Intel的奔腾二说成慢如蜗牛。当然了，广告夸得再好，谁用谁知道，客户又不是傻子，真正的铁杆果粉又有几个。所以苹果在Mac OS一系列重写和修正失败后决定收购NeXT，把NeXTSTEP当作构建Mac OS X的基石（见《Mac OS X 背后的故事一》）。
NeXTSTEP迁移至PowerPC
NeXTSTEP 使用的Mach＋BSD＋DriverKit内核支持，属于类Unix系统，其天生具有良好的移植性（这也是当年的Solaris及AIX能那么快完成 PowerPC移植的原因）。Unix早年被设计时，为了能移植在各种大型机上，Denis Ritchie特地发明了C语言并极力减少机器码使用比重。后来的BSD系列为了能在各大学使用，也秉持了当初Unix设计的态度，并且尽可能地写平台无 关代码。例如现代的FreeBSD分支中，机器码占内核总代码的比重差不多为0.6％，而所有跟架构相关代码在内核中才占13.6％左右。这无疑为 NeXTSTEP这样的BSD分支移植到各架构上创造了得天独厚的优势。
NeXTSTEP支持 68K、x86、PA-RISC和SPARC架构，但颇有意味的是它之前不支持PowerPC架构。之前，苹果曾扶持Linux内核作为单一的服务运行在 Mach内核上，并把整套操作系统往PowerPC上移植，这就是MkLinux。MkLinux不但为Linux对PowerPC的支持作出了巨大贡 献，也为苹果使用NeXTSTEP扫清了最大的障碍。这些开发多源于开源社区，但使得苹果在很早就具备跨平台的能力（哪怕跨Intel和PowerPC这 种字节序完全不同的平台）。
NeXTSTEP另一个有趣的内核功能是支持称为胖二进制文件的技术。NeXT公司自己定制的GCC编译器可以 通过交叉编译，产生一个包含所有架构可执行码的二进制文件。这个文件可以在一个特定硬件平台上解出该平台原生版本的机器码执行。这个技术在Mac OS到Mac OS X的迁移中并没有被公布，却成为2005年往英特尔迁移时的核心技术之一。
NeXTSTEP有了这两个很好的条件后， 往PowerPC的移植并没经历太多的挫折，并且在前期一度准备x86平台和PowerPC平台“两手抓，两手都要硬。”1998年的MacWorld 上，乔布斯声称Rhapsody最后将成为Mac OS X Server 1.0版。而完整的Unix层代码后被释出，成为以Darwin为名的开放源代码软件。读者如果移步 http://opensource.apple.com/，会发现即使是在早期的Mac OS X 10.0代码中也是包含x86支持的。
Intel的捷径
显然，Mac OS X支持PowerPC是为了对老苹果用户负责，但对于x86平台的支持，不能不说Jobs早早地为后来的迁移做好了两手准备。的确，在早期，PowerPC这套RISC的架构确实比Intel好，无论在速度还是准确性上。跑分测试中PowrePC遥遥领先，而且，由于Intel芯片中的数表错误，造成其芯片计算浮点数运算时在某些场合会算错。Intel在20世纪90年代中后期一直力推奔腾4，但由于流水设计问题，其性能甚至不如奔腾3。 但Jobs在这时，目光却看得更实际、更远。
Intel毕竟不是傻子，他们有比别的公司多得多的钱投入研究，所以他们有足够多的资源去定下五年甚至十年后的目标（PBS电视纪录片《America Revealed》）。对于自家芯片各种设计上的缺陷，他们自己是损失者，此学得也比别家更快。例如前面提到，x86不是一个RISC的芯片，Intel在1995年发布的Pentium Pro中找到了通往RISC的捷径，把ISA换为RISC会破坏x86架构的兼容性，所以我的架构必须依然使用老指令，但这不代表我的处理器读入x86指令后，不能翻译成别的指令。Pentium Pro在取到一条x86指令时，硬件解码器会把一条CISC的x86指令解码成符合RISC风格的若干条微指令，因此，除了在起跑线上起跑慢了些以外，在解码后，Intel芯片执行的代码相对于PowerPC，技术上不存在任何劣势。指令在暂存器重命名后，通过投机执行绕过风险，便能并发、快速地进行乱序执行。
Intel是大规模量产，所以对于每块芯片的平均造价要比PowerPC低很多。PowerPC的芯片价格无疑抬高了Mac电脑的成 本，不但造成Mac用户的小众规模，同时在Intel大步迈进的同时，摩托罗拉却止步不前。尤其是Intel较早地意识到了移动芯片的重要性，开始对芯片进行节能优化设计，而PowerPC跑起来就像是个电暖炉。这使得苹果发布的笔记本电脑芯片主频一直远落后于台式机，并且在后期其台式机也需要大量泠却。
这引发了Jobs和摩托罗拉的CEO Chris Galvin的争吵（《Jobs传》）。1997年，Jobs回到苹果后，曾立即决定停止授权同类电脑制造商使用麦金塔操作系统。他打电话向Galvin提议， 如果摩托罗拉加速研发可用于笔记本电脑的芯片，那么苹果公司可能会考虑为摩托罗拉破例，授权其StarMax Mac兼容机使用麦金塔操作系统。两人的对话越来越激烈，Jobs对高尔文说，摩托罗拉的芯片烂透了。高尔文也是个有脾气的人，立即反驳，Jobs挂了他的电话，摩托罗拉从此停止生产StarMax电脑，而Jobs则开始暗中计划抛弃PowerPC芯片，转而投向Intel的怀抱。
## Mac OS X 背后的故事（十五）向 Intel 迁移！（中）
苹果暗中计划放弃PowerPC芯片后，组成了秘密团队希望使每个版本的Mac OS X都能在Intel的x86平台上无缝运行，与此同时，在HP的说服下，Intel在1999年开发出了Itanium处理器，但这款处理器却存在着两个致命的缺陷，这给竞争对手AMD留下了可乘之机。
暗度陈仓，苹果系统向Intel迁移
在Steve Jobs暗中决定抛弃PowerPC芯片转投Intel时，PowerPC在技术上并非没有优势，如果Mac OS X还没成型就对底层架构作如此大的变动，会得罪所有仅存的苹果用户，让苹果面临崩溃。当时的苹果己经弱得经不起什么折腾了，同时也需要IBM和 Motorola的支持去跟Microsoft竞争。
此外，如果在这时选择倒戈，很容易会使苹果沦为一家PC软件公司——之前 NeXTSTEP就是这个下场，软件数千份地卖出去，机器却卖不动，结果只能把硬件部门彻底关闭。而苹果现在的利润全在硬件上，如果宣称支持Intel， 很容易把自己逼上绝路。因此，Steve Jobs决定忍耐。
在产品上，苹果从之前跨架构的Rhapsody砍掉对x86的支持，转为只支持PowerPC一种硬件。你想用我家的Mac OS X系统？那么你只能买我的机器。
每 年的MacWorld或WWDC都会有环节不遗余力地嘲笑Wintel联盟。例如1999年他和Phil Schiller同学卖力地介绍PowerPC的AltiVec可以实现数据层面的并行，而且比Intel芯片快得多，在2001年7月18日的 MacWorld上，Steve Jobs请主管硬件的副总裁Jon Rubinstein介绍The Megahertz Myth，通过举例、列数字、作比较等各种技巧，论证虽然Intel芯片的主频比PowerPC高一倍，但Intel那群白痴使用比PowerPC长几倍 的流水，因此我们PowerPC芯片依然比Intel芯片快一倍。这次讲话通俗易懂地解释了流水、分支预测等高深的术语，简直可以称为计算机处理器知识的 科普视频。
在广告上，苹果除了之前的一些对比广告外，还推出了一系列好玩的嘲讽短片，例如Toasted Commercial，现在看来好像正好说明了PowerPC系列芯片的高功耗。
在产品介绍上，甚至很多PowerPC的缺陷都被包装成亮点，例如Power Mac G5的介绍短片，金牌设计师Jonathan Ive还专门出镜，说PowerPC太强大了发热量好高，所以我们得给它设计了一个很拉风的风扇云云……
但这只是外在的表现。这段时期，Steve Jobs在严格规划每个版本的Mac OS X时，专门秘密组织了一小班人马，这组人有个秘密代号——Marklar，最早于2002年被媒体披露，并在2005年被。这组人做的事， 就是——只要Steve Jobs一声令下，x86版的Mac OS X光盘就能送到开发者或用户手上。
先前讲到，NeXTSTEP具有 良好的移植性。但Mac OS X中，有大量源于Mac OS的代码，如Carbon等，都是存在一定的PowerPC架构依赖的（如Quick-Time、iTunes、Quartz等）。使用了大量 PowerPC特有的AltiVec功能来实现数据并行。因此移植仍具难度，需要改写至Intel的SSE指令。
在2012年的一个Quora回帖上，Kim Scheinberg介绍了苹果如何做到严格的保密措施，其中提到了Marklar的诞生。
2000 年她丈夫John为了和亲人团圆主动请缨要做Intel版本的Mac OS X。十八个月后，他回到组里报告成果，老板Joe看后大为满意，立刻拉来了分管技术的高级副总裁Bertrand Serlet。Bertrand问“如果我买个索尼的Vaio，你多长时间能把Mac OS X移植上去？”John回答“不用很长时间。” “两周还是三周？”“两三小时吧”。Bertrand Serlet遂让人买了台索尼机器，果然数小时后Mac OS X就在机器上跑起来了。于是，John的工作成为Marklar团队的起始点。
从PowerPC往Intel移植最困难的地方在于 PowerPC提供单指令多数据并行的功能AltiVec（后称为Velocity Engine）来实现高维向量、矩阵运算的硬件加速，这有点像Intel的SSE，但需要在代码里用特别的语句调用，这在QuickTime、 Quartz中常常用到。因此苹果把AltiVec包装成一个名为Accelerate的库，分别在两个架构上映射到AltiVec指令和SSE指令。这 个库提供了所有的BLAS、LAPACK功能并提供了非常高效的实现，做数值计算的同学不妨关注一下。
Itanium的诞生
有了Marklar团队的成果，接下去只是何时转换到x86架构平台的问题。但这时，Intel却持续走低，苹果似乎有了一个除Intel以外的选择——AMD。
在1989年，HP认为RISC架构将来会遇到每周期只能执行一个指令的瓶颈。所以想搞一套名为EPIC的新架构。但由于HP不具备研发处理器的资本，所以在1994年拉拢Intel跟它以EPIC为基础，合搞一套叫IA-64的处理器。
先前提到，为了使代码高效地执行，当时Intel已经做出了超纯量乱序执行的Pentium Pro架构。整个框架的原理是读入一系列的指令，把每个指令分解成RISC分格的微指令，使用暂存器重命名等算法来计算并移除指令的依赖关系，然后并发执 行多条语句，达到一个时钟频率能够执行多个指令的目的。
但HP的忽悠能力比较强，它对Intel说：“为什么我们需要由硬件实现乱序执行 呢？你们的处理器为了把x86指令解成微指令，需要一个比RISC架构复杂得多的解码器。而为了达到乱序执行，你们设计了一整套复杂得多的逻辑去判断执 行，这是计算机在运行中所需要付出的代价！
现代的编译器早就足够高级了，完全能在编译时判断语句的依赖关系，并且自动进行暂存器命名等一系列的算法，所以在程序编译时就能给出一个个指令包，每个指令包包含了一系列能同时并发执行的RISC指令。
我 们完全可以设计一个新指令集，称为超长指令字架构（VLIW，Very Long Instruction Word），一个指令包中的所有指令都会转化成一个VLIW语句。这样，当VLIW语句通往芯处理器时，处理器就无需进行复杂的解码（因为指令本身是 RISC风格的）、逻辑判断（因为编译时己判断好了）、暂存器重命名、乱序执行算法，只要解开一个VLIW指令让分配器并发执行就行了。
因此，我们的编译器就能决定让这些小指令同时执行于单一周期，处理器能够简单地执行这些指令而不需要很复杂的架构去决定哪些指令能够并行执行。”
Intel被这么一忽悠觉得IA-64大有前途，如果搞出来，会被多数的企业系统制造业采用，所以开始下血本开发。由于1998年正值电影泰坦尼克号热映，Intel在1999年10月4日发布该处理器的官方名称为Itanium。
Intel 认为，Itanium将会是个终级架构，可以解决一切问题，将会是未来的发展方向。虽然指令集和x86完全不兼容，但随着服务器领域和将来的桌面领域从 32位迁移到64位，指令集肯定是需要做出重大改变的，利用这个机会，Intel自然可以自由采用一种新指令集和过去划清界限。于是索性就不用开发64位 的x86了，逼着大家都用Itanium就可以了。
正当Intel做着天上降下黄金雨的美梦时，它完全没有意识到灾难己经临近。Itanium的设计看似完美无缺，但他们没有意识到其中两个重大的问题——指令宽度和Cache。
“短板”原理在Itanium上应验
x86的好处是，虽然这是一个CISC的指令集，但这个指令集对程序执行的逻辑没有额外的限制，所以只要Intel保证产生的运算结果是一致的，就可以以任何方式实现这个指令集，例如解成RISC、增加超纯量模块、调度成乱序并行执行，Intel想怎么做都可以。
但Itanium让编译器决定一切，编译器自动判别依赖关系并产生一个个指令包，每个包内的指令不存在依赖关系，所以指令集一公布，要想改就困难了。例如每 个VLIW指令包是包着三个RISC指令的，如果若干年后做出了能并行执行六个指令的芯片，那它能一起执行两个VLIW指令吗？
醒醒吧，因为这两个VLIW指令很可能有依赖关系！那可以重新让处理器判断依赖关系后再执行吗？该吃药了——Itanium花那么多血本就是想让编译器搞定一切而不用处理器判断！
那怎么办呢？只有两个办法：其一是一次运行三条指令（即使我的机器有能力执行六个宽度），所以程序执行效率只有一半；其二是要求每有新一代的芯片出现，所有 程序都要重新编译才能完全发挥芯片设计的理论效能。这是让人无法忍受的一件事——难道今后软件发布出来，要为各个指令宽度的Itanium各做一个版本吗?
更麻烦的问题是Cache。Cache是处理器上用于减少处理器访问记忆体所需平均时间的部件。其容量远小于内存，但速度却可以接近处 理器的频率。当处理器发出内存访问请求时，会先查看Cache内是否有请求资料。如果命中，则不经访问记忆体直接返回该资料；如果不存在，则要先把记忆体中的相应资料载入Cache，再将其返回处理器。
与前面那种情况相比，这需要更长的等待时间。至于什么资料是在Cache内的，完全是由计算机程序运行时决定。编译器在编译时是无法预测程序在执行时所使用Cache的情况的——这一切完全是随机的。对于一个可以乱序执行的处理器而言，如果某 条数据的结果不在Cache里，可以动态调度，先执行别的语句，从内存里取出，再执行这条语句。
像Itanium把可以并发的程序指令捆在一个包中，如果这个包中所需要的变量还在内存里，那处理器就什么都干不了，只能等从内存数据搬到Cache中。所以，Itanium的执行效率不会好于乱序执行的处理器。
正当Intel一步步坚定不移地在死路上越走越远时，Intel的竞争对手AMD却没闲着。
Intel不做x86架构的64位版？我们做（2003年AMD抢先于Intel发布了Athlon 64，随后又推出了面向主流消费市场的Athlon 64 X2）！Intel不做x86架构的多核处理器？我们做（2005年4月22日，AMD领先于Intel率先发布了拥有双核的Opteron处理器）！
跑分测试下来，AMD技术在许多方面远胜Intel，其中尤其以浮点运快著称。同时，AMD允许用户选择比Intel高的频率来跑运算（当然用户自己要承担CPU高频烧毁的风险），所以很多计算机爱好者更青睐AMD。


## Mac OS X 背后的故事（十六）向 Intel 迁移！（下）
**Intel意识到了自己的错误，果断终止了Itanium的开发，并重振旗鼓研发出了Pentium芯片和一系列的后继产品。这一举措让苹果看到了与之合作的希望，它们历时三年完成了软件和硬件的底层移植，之后又先后运用了模拟器和通用二进制技术，最终彻底完成了这场“浩荡”的大迁移。**

#### 成大事者，必有远见
由于AMD技术在很多方面远胜Intel，且允许用户选择比Intel高的频率来跑运算，所以受到了很多计算机爱好者的青睐。另外，AMD不断下压其产品价格，一时间门庭若市，消费者络绎不绝。甚至Intel的好朋友微软也前来插上一脚，联合AMD搞出了X86-64架构的Windows XP。昔日风光的Intel顿时成了业界人人欺负、人人嘲笑的对象。
就是在这个节骨眼上，苹果正在计划把整套Mac产品线迁移到x86上。他们自然之道Intel的Itanium必定会失败，也在先前多次嘲笑使用NetBurst框架的Pentium 4的长流水技术效能是多么的低，他们之道AMD会给出更低的价格，也知道AMD的64位技术，连x86平台都不用迁移了，可以直接迁到x86-64上。
但在这里我不得不佩服苹果在这个决策上的远见。他们没有选择AMD，而是选择了但是不被看好的Intel，哪怕在前一年他们还在开发者大会上嘲笑Wintel联盟。他们做出这个明智的选择，是因为Intel在这时，已经充分意识到自己的错误，正在迎头赶上。Intel基本砍掉了Itanium的开发工作，工作重心重新回到了x86，而之前的x86，Intel倾向于使用NetBurst。在长流水的NetBurst框架中，整条流水长为20步。的确，把长流水加长，可以简化每一步操作，从而增加时钟频率，使程序高速地执行。但这时遇到两个问题。如果分支预测做出了错误的猜测，那进入整条流水的指令都得扔掉换取新的指令重算。因此，误判一次，长流水将付出大得多的误判代价。另一方面，时钟频率不可能无限制的加快，把时钟频率加快一倍，能耗会成为原来的四倍多，散热、待机时间都会成问题。
Intel向苹果展示出他们的蓝图--他们早早地意识到移动计算领域的重要性，所以NetBurst必定走不通。于是他们立即回头，弃掉整个方案，使用之前废弃的P6技术，重振旗鼓，研发出Pentium M移动芯片，并打算在此基础上发展出一系列后继产品（Core、Nehalem系列技术，其中包括了和AMD类似的64位技术）。他们向苹果承诺自己即将推出的产品不但可以在性能上干翻别的处理器，更会在能耗上取胜。
苹果在Intel展示的蓝图中，看到了自己的未来--他们之前是多么希望PowerPC研发出3GHz的芯片，但几年过去了却丝毫不见影子；他们是多么想把PowerOC G5放到笔记本电脑或iMac上，但为了冷却它，苹果得安装巨大的风扇，且电池撑不了多久。如果全套使用Intel的方案，他们就可以马上把高性能低功耗的产品推向市场。因此，虽然AMD当时占领了越来越多的桌面份额，但由于功耗问题，它依然不是苹果的菜。Intel和苹果两大公司一拍即合，开始合作。所以2005年6月6日WWDC上，Steve Jobs胸有成竹地走上台，发布往Intel平台迁移的消息。他特别指出，如果以消耗的能源作对比基准，以瓦特作单位。Intel处理器的表现要远远好于PowerPC处理器。而在手提电脑的设计里，这是一个非常重要的考虑因素，这一性能指标将严重影响电脑的寿命与使用时间。
这个迁移计划包括硬件和软件两个部分。硬件部分的整个迁移计划准备在2006年6月开始行动，在2007年末结束，但实际上苹果的平台迁移进行得比料想中快得多。首代配备了Intel处理器的Mac电脑于2006年1月推出，并在2006年10月推出最后一款需要迁移至Intel平台的产品--Xserver。最终Xserver服务器于2006年12月推出，硬件层面的Intel平台迁移此时宣告完结。Intel实现了其原先在性能和功耗上的承诺。从速度上，Intel的Core Due处理器的实际性能表现基础可以与原先的Power Mac G5台式机媲美；能耗上，苹果的iBook、PowerBook被以MacBook、MacBook Pro重命名，且基本都使用了当时较新的芯片类型。更夸张的是，2006年年中推出的Mac Pro替换掉了原先的Power Mac，因为根本不需要先前提到的高级散热系统，所以巨型的风扇被移走，腾出的空间足够让用户装更多的硬盘。
软件部分则完全依赖于Marklar计划所打下的底子。那天在WWDC现场，Steve Jobs突然告诉观众，舞台上那台用了一上午的演示电脑，其实是Intel核心的，他特地点开了系统配置窗口让观众确认，引来了观众的惊异声。他展示了多个Mac OS X的自带软件，可以看到，虽然还是测试版。在一年后的MacWorld上，Jobs自豪地声称，Mac OS X的8600行代码，已经完全从PowerPC迁至Intel。2009年8月28日发布的Mac OS X 10.6 Snow leopard仅支持Intel处理器，标志着对PowerPC支持的结束。

#### 多管齐下，为应用移植扫清障碍
操作系统只是底层，用户更关心的是整个应用程序生态圈。Java程序和Dashboard Widget程序本身都是和平台无关的，所以用户不用担心迁移问题。那对于之前用户所用的PowerPC程序怎么办呢？苹果使用了当初解决迁移68k到PowerOC上的老办法----模拟器。这款名为Rosetta的模拟器会把用户程序翻译成Intel x86的指令。在演讲当天，Steve Jobs演示了PhotoShop、Microsoft World等用户喜闻乐见的程序，运行都很流畅。苹果系统中的所有系统库，也提供了PowerPC程序调用。所以Rosetta最终的指令都会转成Intel计算指令和向XNU核心的系统调用。对于用户使用的大多数图形界面程序而言，系统调用居多，且大多时间是计算器闲置等待用户输入，因此，使用Rosetta虚拟的程序，其性能问题并不明显，用户普遍表示压力不大。
Rosetta毕竟只是无奈之举，对于应用软件开发者，苹果则呼吁他们赶紧把程序在x86平台重新编译。为了减轻开发人员移植平台时的负担，苹果推出了一项新技术----通用二进制程序（Universal Binary）。其实这和之前介绍的胖二进制没有任何区别，只是为了这次迁移的商业宣传的需要改了个新名字而已。在用一个程序包中同时为两种架构提供二进制码，使应用程序能以原生形式运行在使用PowerPC或Intel x86的Mac电脑上，